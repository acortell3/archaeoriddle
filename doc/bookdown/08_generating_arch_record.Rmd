# Generate final archaeological record {#final-output}

Now that all the pieces are in place we need to combine them to generate files that can be shared with people in order for them to guess the original parameters.

To summarize what we have so far:

1. we generated a fake environment in Chapter \@ref(env)
2. we localised sites on the map and defined a population growth process in Chapter \@ref(popgrowth)
3. we defined rules to decide how population move and enter in conflict when they grow in Chapter \@ref(conflict)
4. we run simulation these process of grwoth, conflict and migration on the environement for long time in Chapter \@ref(main-simu)
4. we defined processes that use this simulate growth to generate an archaeological record in Chapter \@ref(recgen)
5. we defined processes that transform this archaeological record using credible loss \@ref(recgen}

Here we will use all these previous steps to generate csvs that can be shared. In this chapter we will use the simulation run in the Chapter \@ref(main-simu) ; if you want to generated new 'fake'-dataset, different from the one that have been presented in the original challenge and that will be described in the chapter \@ref(original-challenge), you will want to run longer simulation, and choose among different run on the looks interesting/realistic. We provide a script `./scriptmini.R` that to give some idea about how to automatize these run and how to choose among them.



## Using sites size to generate deposit

This has been done using file `dateGeneration.R`, we will describe it here now.

First we get the rasters defining the environment (If you followed the book since the beginning they should be already in memory but in case you didn't we we reload them here:

```{r getRaster-ex,eval=T,cache=F}
height.ras=rast("data_toshare/dem_raster.tiff")
height.wat=height.ras
height.wat[height.wat>mean(height.wat[])]=NA
Nts=onesimu$Nts
plotMap(height.ras,height.wat)
```

Using `Rec_c` , `short_loss` and `long_loss`, that we presented in the Chapter \@ref(recgen) & \@ref(recloss), we generate deposit. This can take long time if the simulation included a lot of sites, spanning over long period of time. Here we first generate all deposit from the matrix `Nts` generated during the simulation of the Chapter \@ref(main-simu) and then apply all loss functions together:


```{r doloss-ex,eval=T}
#All in one:
alldeposit=lapply(1:ncol(Nts),function(s)Rec_c(sapply(Nts[,s],A_rates), InitBP = 7500,ts=ncol(Nts),r = 0.2, max_bone_thickness = "m"))
allLosses=lapply(1:length(alldeposit),function(ind){
    Rec=alldeposit[[ind]];                    
    Rec=apply(Rec,2,short_loss,.6)  #apply short loss
    Rec=long_loss(Rec,.9997,7500) #apply long loss
    return(Rec)
})
rm(alldeposit)
```

Once this is done, we have a list with all the date available from all site that have existed during our simulation. Realisticly, not _all_  date will be recovered for a given archaeologicl sites, thus we cap the maximum number of sample available per sites. As you will see in the original challange presented in the Chapter \@ref(original-challenge), we assume that the biggest sites -- the one that will received most funding and attention, will very likely get 30 dates. We thus subsample the number of dates for smaller site given this ration of $\frac{30}{n_{\text{largest}}}$. Here simulation have been greatly shortened, thus sites have way less samples. We thus cap the larges sites to have only 80% of the dates it generate, and sample the other sites using this ratio.

```{r removesmall-ex, eval=T}
maxSites=max(sapply(allLosses,sum))
nsample=round(sapply(allLosses,sum)*(30/maxSites))
allRemainingDates=lapply(seq_along(allLosses),function(r)extractDates(allLosses[[r]],n=nsample[r]))
rm(allLosses) #object are big, need to free memory
```



```{r getadates-ex,eval=T,out.width="45%",fig.show="hold"}
expname="exn"
plotMap(height.ras,height.wat,paste0("final after losses"))
plot(sites[1:10,],cex=3*(lengths(allRemainingDates)-1)/(29),pch=21,add=T,bg=rainbow(2,alpha=.6)[as.factor(sites$culture[1:10])])

dates=unique(unlist(allRemainingDates))
dates=rev(sort(dates[!is.na(dates)]))
plot(table(unlist(allRemainingDates)))
totallDatesRemains=sapply(allRemainingDates,function(i)table(factor(i,levels=dates)))
saveRDS(allRemainingDates,file=file.path(foldtmp,paste0(expname,"_dates.RDS")))
```

From this we have, for every site, a list of date(s)

This has been done using the script `exploreDate.R` but will be explained here:


Loading simulation results, green are the sites who survived, dots are all the site that existed.

```{r getfakeresults-ex,cache=F}

allsites=vect(file.path(foldtmp,"allsites.shp"))
if(class(allsites)[1] == "PackedSpatVector")
    allsites=terra::vect(allsites)
plotMap(height.ras,height.wat)
plot(allsites,add=T)
plot(allsites[Nts[nrow(Nts),]>0,],add=T,pch=21,bg="green",cex=Nts[nrow(Nts),]/60)
```

Loading dates:

```{r getfakedates-ex,cache=F}
dates=readRDS(file=file.path(foldtmp,paste0(expname,"_dates.RDS")))
```

Keep sites with foundable dates

```{r extractdates-ex,cache=F}
foundsites=allsites[lengths(dates)>0,]
foundsites$numdates=unlist(lengths(dates[lengths(dates)>0]))
founddates=dates[lengths(dates)>0]
```

Remove BP to the dates, add some random variation

```{r addstdev-ex,cache=F}
stdpool=c(20,30,40,50,60,80,100,120)
founddates=lapply(founddates,sort)
founddates=lapply(founddates,gsub,pattern=" BP",replacement="")
founddates=lapply(founddates,rev)
founddates=lapply(founddates,function(i)paste0(i," ± ",sample(stdpool,length(i),replace=T,prob=c(3,3,3,3,2,2,1,1))," BP"))
foundsites$dates=sapply(founddates,paste0,collapse=" | ")
plotMap(height.ras,height.wat)
plot(foundsites,cex=foundsites$numdates/20+1,pch=21,bg=as.factor(foundsites$culture),add=T)
```

## Split environment in a grid

Split the environment in grids and extract date for each grid

```{r plotallfoundiste-ex,cache=F}

leftdates=dates[lengths(dates)>0]
plotMap(height.ras,height.wat)
plot(foundsites,cex=foundsites$numdates/20+.1,pch=21,bg=1,add=T)
squares=st_make_grid(height.ras,.5)
plot(squares,add=T,col=adjustcolor(rainbow(length(squares)),.35))
text(st_coordinates(st_centroid(squares)),label=1:length(squares),col="white")
text(st_coordinates(st_centroid(squares)),label=1:length(squares),col="white")
```

Public selection

```{r getpublicsele-ex,cache=F,out.width="45%",fig.show="hold"}
plotMap(height.ras,height.wat)
plot(foundsites,cex=foundsites$numdates/20+1,pch=21,bg=as.factor(foundsites$culture),add=T)
selection=sample(seq_along(squares),4)
inter=st_intersection(st_as_sf(foundsites),squares[selection])
while(nrow(inter)<5){
    selection=sample(seq_along(squares),4)
    inter=st_intersection(st_as_sf(foundsites),squares[selection])
}
plot(squares[selection],add=T,col=adjustcolor("blue",.3))
plotMap(height.ras,height.wat)
plot(st_geometry(inter),add=T,bg=rainbow(2,alpha=.6)[as.factor(inter$culture)],pch=21,cex=1+inter$numdates/10)
```

### Giving name to the publicly available data

On the original challenge we used: [fantasynamegenerators.com](https://www.fantasynamegenerators.com/fantasy-town-names.php) to choose nice, randomly generated  name. You will see in the section \@ref(naming) that we positionned them with cultural relevent group, although this has no impact on the results. Here we took all the name we had for the original challenge to randomly assignate some for you custom world.

```{r namesites-ex,cache=F}

site_dist=st_distance(inter)
potname=c("Farwallow" ,"Bearcall" ,"Dustscar" ,"Clearreach" ,"Rabbithole",
"Épibéliard" ,"Cololuçon" ,"Pulogne" ,"Haguemasse" ,"Auriteaux" ,"Bourville" ,"Banau" ,"Montnesse" ,"Bannet" ,"Alenlon", "Roullac" ,"Genneville" ,"Vinlès" ,"Antonnet" ,"Courtou" ,"Beaulogne" ,"Coloville" ,"Sarsart" ,"Soilon" ,"Cololimar","Zava" ,"Catadrid" ,"Tegon" ,"Alicia" ,"Mulid" ,"Zararbella" ,"Malid" ,"Cásca" ,"Granalejos" ,"Segorez" ,"Terteixo" ,"Astumanca" ,"Galle" ,"Talona" ,"Girovega" ,"Albanada" ,"Nadoba" ,"Senca" ,"Vallanca" ,"Taville")

u=0
while(length(potname)<nrow(inter)){
    u=u+1
    potname=c(potname,paste0(potname,u))
}
sitesnames=sample(potname,nrow(inter))

inter=cbind(inter,sitesnames)
plotMap(height.ras,height.wat)
plot(st_geometry(inter),add=T,bg=rainbow(2,alpha=.6)[as.factor(inter$culture)],pch=21,cex=1+inter$numdates/10)
text(st_coordinates(inter),inter$sitesnames,cex=.8)
```

Export csv and data for each public square

```{r exportpublic-ex,eval=F}

inter$sitesnames=sitesnames
for(g in selection){
curr=inter[inter$ID==g,]
coords=st_coordinates(curr)
    write.csv(file=paste0("square_",g,".csv"),cbind.data.frame(sitename=curr$sitesnames,lon=coords[,1],lat=coords[,2],dates=curr$dates,economy=curr$culture))
}

```

The csv generate for this specific run of the bookdown can be [downloaded here]('dataset')

Export csv and data for all ever square

```{r exportprivate-ex,eval=F}

allsites=st_intersection(st_as_sf(foundsites),squares[-selection])

for(g in (1:length(squares))[-selection]){
curr=allsites[allsites$ID==g,]
coords=st_coordinates(curr)
    write.csv(file=paste0("square_",g,".csv"),cbind.data.frame(lon=coords[,1],lat=coords[,2],dates=curr$dates,economy=curr$culture))
}

ld=strsplit(inter$dates," \\| ")
ld=lapply(ld,function(i)gsub(" ± .*","",i))
inter$start=sapply(ld,max)
inter$end=sapply(ld,min)

```


Some maps we use and did for fake papers and social media etc... 


```{r randommaps-ex,out.width="30%",fig.show="hold"}

## plotting oldschool map

par(mar=c(0,0,0,0),oma=c(0,0,0,0))

plot(height.wat,col=adjustcolor("light blue",.4),reset=F,legend=F,axes=F)
contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels="",bg="light blue",add=T)
plot(st_geometry(inter),pch=4,add=T,lwd=.3)
plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=.8,col=as.factor(inter$culture),alpha=.8)
box(which="outer")

old=inter[inter$start>7180,]
ne=inter[inter$start>6800 & inter$end<6900,]

plot(height.wat,col=adjustcolor("light blue",.4),reset=F,legend=F,axes=F)
contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels="",bg="light blue",add=T)
plot(st_geometry(old),pch=4,add=T,lwd=.5,cex=3)
plot(st_geometry(old),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(old$culture),alpha=.8)
box()


plot(height.wat,col=adjustcolor("light blue",.4),reset=F,legend=F,axes=F)
contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels="",bg="light blue",add=T)
plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3)
plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8)
box()


plot(height.wat,col=adjustcolor("light blue",.4),reset=F,legend=F,axes=F)
contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels="",bg="light blue",add=T)
plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3)
plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8)
box()

plot(height.wat,col=adjustcolor("light blue",.4),reset=F,legend=F,axes=F)
contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels="",bg="light blue",add=T)
plot(st_geometry(ne),pch=4,add=T,lwd=.5,cex=3)
plot(st_geometry(ne),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(ne$culture),alpha=.8)
box()
```

More maps for twitter:

```{r randommaps2-ex}
plot(height.wat,col=adjustcolor("light blue",.4),reset=F,legend=F,axes=F)
contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.2,labels="",bg="light blue",add=T)
plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3)
plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8)
box()
sel=inter[c(20,2,15,36),]
text(st_coordinates(sel),sel$sitesnames,cex=.8,pos=c(1,2,2,4))
text(x = -1, y = .7, labels = "❤️", adj = c(0, 0), cex = 3, col = "black", font = 1)
text(x = -1, y = 1.2, labels = "🔥 ", adj = c(0, 0), cex = 3, col = "black", font = 1)
text(x = -1, y = 1.2, labels = "⚔️ ", adj = c(0, 0), cex = 3, col = "black", font = 1)
text(x = -1.2, y = 1.8/2, labels = "???? ", adj=c(0,0), cex = 3, col = "black", font = 1)
```
More maps!! (the coolest)


```{r randommaps3-ex}
plotMap(height.ras,height.wat)
contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.2,labels="",bg="light blue",add=T)
plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3)
plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8)
coastline=st_cast(st_as_sf(as.polygons(height.ras>mean(height.ras[])))[2,],"MULTILINESTRING")
plot(coastline,add=T,lwd=1.1,col="black")
box()
sel=inter[c(20,2,15,36),]
text(st_coordinates(sel),sel$sitesnames,cex=.8,pos=c(1,2,2,4))

```


```{r}

plotMap(height.ras,height.wat)
contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.2,labels="",bg="light blue",add=T)
plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3)
plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8)
coastline=st_cast(st_as_sf(as.polygons(height.ras>mean(height.ras[])))[2,],"MULTILINESTRING")
plot(coastline,add=T,lwd=1.1,col="black")
box()
sel=inter[c(20,2,15,36),]
text(st_coordinates(sel),sel$sitesnames,cex=.8,pos=c(1,2,2,4))
#text(x = -1, y = .7, labels = "🍻", adj = c(0, 0), cex = 3, col = "black", font = 1)
text(x = -3.4, y = .7, labels = "🍻 ", adj = c(0, 0), cex = 10, col = "black", font = 1)
text(x = -1.8, y = .7, labels = "👍 ", adj = c(0, 0), cex = 8, col = "black", font = 1)
text(x = -.5, y = .7, labels = "🍔 ", adj = c(0, 0), cex = 6, col = "black", font = 1)
#text(x = -1, y = 1.2, labels = "⚔️ ", adj = c(0, 0), cex = 3, col = "black", font = 1)
#text(x = -1.2, y = 1.8/2, labels = "???? ", adj=c(0,0), cex = 3, col = "black", font = 1)


```
