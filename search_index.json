[["index.html", "Methods Riddles, the ultimate revelations Preface", " Methods Riddles, the ultimate revelations CDAL 2024-03-05 13:52:18.909528 Preface This is a very first draft to setup a github hook that compile a bookdown in a private space To compile the book: bookdown::render_book(&quot;.&quot;) For this to be successfull you will need a few aditional packages to install: needed=c(&quot;DiagrammeR&quot;,&quot;viridis&quot;,&quot;terra&quot;,&quot;sf&quot;,&quot;igraph&quot;,&quot;rayshader&quot;,&quot;printr&quot;) ## printr for bookdown compilation success=sapply(needed,require,character.only=T) sapply(needed[!success],install.packages) ## named list() success=sapply(needed,require,character.only=T) These package will very likely need other package that will depend on your operating system, so check the error message from the previous commands! If you want to use the function and methods described in the bookdown you will need to install the archaeoriddle package. With devtools installed, you can do: devtools::install_github(&quot;acortell3/archaeoriddle&quot;) Once this is done: library(archaeoriddle) ## ## Attaching package: &#39;archaeoriddle&#39; ## The following object is masked from &#39;package:base&#39;: ## ## environment The book can also be found already compiled here. "],["introduction.html", "1 Introduction 1.1 What is archaeoriddle? 1.2 What will you find in this bookdown? 1.3 What can you do with this?", " 1 Introduction 1.1 What is archaeoriddle? Archaeoriddle is a collaborative project at the Computational and Digital Archaeology Laboratory (CDAL) from the Department of Archaeology, University of Cambridge. The project started with an idea to develop an ABM to simulate an interaction process in the imaginary world of Rabbithole between two fictitious groups: the hunter-gatherers called rabbitskinners and the farmers called poppychewers. Through this world, the project could explore archaeological use of data and methods in a controlled environment to learn more about the act of research. The project has also produced a large amount of media content for dissemination and engagement, most of which can be found on the various social accounts linked to the project (here or here). There, you will also find all of the information related to the project (or most of it anyway). In brief, the idea was to create a virtual world were we, as developers, know the full extent of what happened in the archaeological past, but those outside the project would be limited to a partial view of the data, reflecting real life where the archaeological record is incomplete. Given this limited dataset, interested participants were given questions to answer with their own chosen methods. We created a map with 100 grids of which only 5 are shared commonly, and each participant has the right to request 5 more of their own preference. All these data has additionally gone through processes of creation and loss emulating the archaeological record. The idea is that each researcher tries to understand what happened so that the results of the different methodologies proposed can be compared. There you will also find all of the information related to the project (or most of it anyway), but in brief, the idea behind it is to create a virtual world where we, as developers, know what happened, but where only partial data are available to the public. With this, there are then some questions which interested participants have to answer with their own methods. In particular, we have created a map with 100 grid squares, of which only five were shared commonly, and each participant had the right to request five more squares of their own preference. Additionally, all data had gone through processes of creation and loss, emulating the archaeological record. The aim was that each researcher tried to understand what happened so that the results of the different proposed methodologies could be compared. The project has been a great success, and the team presented at several conferences (dedicated presentations at CAA conferences 2022 and 2023, as well as several others), culminating with a thought-provoking discussion at the dedicated workshop in the European Association of Archaeologists conference in Belfast (2023) where interested participants presented their proposals. The full project is explained in more detail at the website referred to above. We are continuing to produce more documentation, which will explain even more, but this general picture is what you need to know to use this bookdown document. 1.2 What will you find in this bookdown? This bookdown document provides an explanation of the model used in the creation of the project. Everything has been developed using R. By downloading the package “archaeoriddle” from GitHub, you can reproduce the world of the Rabbithole or adapt it to create your own using the code provided in this bookdown document. This might be useful not only to create a virtual world from scratch while attending to different archaeological constraints, but also provides an excellent exercise to practice making R-based ABMs. Finally, all the data, this includes the data that we produceed (including what’s on the website) or the one that you produce from this is free, and you are free modify to suit your differing needs. We have structured the following chapters as follows: Landscape, climate, and environment: functions and methods to create ‘realistic’ artificial environments. Population growth on multiple sites: functions and methods to design population that grows, dies, moves, and fights. Record formation: functions and methods to generate archaeological record given the population of each site. Record loss: functions and methods to simulate loss of the record through time. Final choice and simulation: functions and methods that explore different patterns of population growth. Generate archaeological remains and squares: functions and methods to create, organise, and share the data. 1.3 What can you do with this? Well, many things! We have mentioned the data already generated (which can be freely downloaded) can be used for your own research purposes or as an educational tool. We encourage you to use the code in this bookdown to generate your own Rabbithole and pose your own research questions with synthetic data. Additionally, this book is also a good document for the development of ABMs in R. All in all, our purpose is not only to bring awareness to the strengths and weaknesses of archaeological methodology, but also to provide material (e.g. methods, theory, and code) for interested researchers so that they can reproduce their own virtual worlds and do their own experiments. Thus, we are proposing a tool that can be used for research, but which is also an excellent testing ground for educational and training purposes. Download things and toy around! Don’t worry, you won’t break anything!! "],["landscape-climate-environment.html", "2 Landscape, climate &amp; Environment 2.1 Temperature and climate Power law Noise from Kimmer &amp; Koening 2.2 Slope and Elevation Perlin-noise for elevation and slope 2.3 Settlements position 2.4 Network, Site Size And Climate – DEPRECATED", " 2 Landscape, climate &amp; Environment 2.1 Temperature and climate If we are going to simulate the interaction between two groups, we are going to need an environment in which they can interact in. This chapter walks you through how to generate a landscape and an environment for your simulated groups to explore. An important part of the simulation is to generate a landscape and an environment. We use the environment function, which in turns uses TK95 to generate a power law noise. TK95R Documentation Power law Noise from Kimmer &amp; Koening Description From tuneR package (implemented in the file Waveforms.R in tuneR source) Based on Timmer &amp; Koening (1995) Usage TK95(N, alpha = 1) Arguments N the length of the timeserie to generate alpha the slope of the power distribution (called omega in whitehead) ## Help on topic &#39;environment&#39; was found in the following packages: ## ## * base ## * archaeoriddle To generate a fake climate with various properties: tstep &lt;- 1000 faketemp &lt;- environment(tstep, omega=3, delta=1.5) + 1.5 plot(faketemp, type=&quot;l&quot;, ylab=&quot;temperature change&quot;, xlab=&quot;time&quot;) You can inspect the code of environment and TK95 functions here: Show code Code ## Function 10. Power law noise from Kimmer &amp; Koening TK95 &lt;- function(N, alpha = 1){ f &lt;- seq(from=0, to=pi, length.out=(N/2+1))[-c(1,(N/2+1))] # Fourier frequencies f_ &lt;- 1 / f^alpha # Power law RW &lt;- sqrt(0.5*f_) * rnorm(N/2-1) # for the real part IW &lt;- sqrt(0.5*f_) * rnorm(N/2-1) # for the imaginary part fR &lt;- complex(real=c(rnorm(1), RW, rnorm(1), RW[(N/2-1):1]), imaginary=c(0, IW, 0, -IW[(N/2-1):1]), length.out=N) # Those complex numbers that are to be back transformed for # Fourier Frequencies 0, 2pi/N, 2*2pi/N, ..., pi, ..., 2pi-1/N # Choose in a way that frequencies are complex-conjugated and symmetric around pi # 0 and pi do not need an imaginary part reihe &lt;- fft(fR, inverse=TRUE) # go back into time domain return(Re(reihe)) # imaginary part is 0 } ## Function 11. Environment generator environment &lt;- function(N, omega, delta, vt=NULL){ ts &lt;- TK95(N, omega) ts &lt;- delta * ts/sd(ts) if(!is.null(vt)) { ts = ts + vt*1:N } return(ts) } 2.2 Slope and Elevation This autocorrelates time series that can be used to adjust temporal change in climate (rain, temperature, etc….). But we also need a way to generate elevation and slope. We can use similar methods to generate 2D autocorrelation. We use here an implementation of what is known as perlin noise found on this stackoverflow.com post. This is the usage of the function: perlin_noiseR Documentation Perlin-noise for elevation and slope Description This function creates slope and elevation with 2-D autocorrelation and noise. Collectively it is called Perlin noise Usage perlin_noise(n = 5, m = 7, N = 100, M = 100) Arguments n Size of the grid in the vector field on one dimension m Size of the grid in the vector field on the other dimension N Size of the final image M Size of the final image on the other dimension Value numeric matrix of size N-1 x M-1 And you can see the code here: Show code Code ## Function 12. Perlin noise perlin_noise &lt;- function( n = 5, m = 7, N = 100, M = 100 ) { # For each point on this n*m grid, choose a unit 1 vector vector_field &lt;- apply( array( rnorm( 2 * n * m ), dim = c(2,n,m) ), 2:3, function(u) u / sqrt(sum(u^2)) ) f &lt;- function(x, y) { # Find the grid cell in which the point (x,y) is i &lt;- floor(x) j &lt;- floor(y) stopifnot( i &gt;= 1 || j &gt;= 1 || i &lt; n || j &lt; m ) # The 4 vectors, from the vector field, at the vertices of the square v1 &lt;- vector_field[, i, j] v2 &lt;- vector_field[, i+1, j] v3 &lt;- vector_field[, i, j+1] v4 &lt;- vector_field[, i+1, j+1] # Vectors from the point to the vertices u1 &lt;- c(x,y) - c(i, j) u2 &lt;- c(x,y) - c(i+1, j) u3 &lt;- c(x,y) - c(i, j+1) u4 &lt;- c(x,y) - c(i+1, j+1) # Scalar products a1 &lt;- sum( v1 * u1 ) a2 &lt;- sum( v2 * u2 ) a3 &lt;- sum( v3 * u3 ) a4 &lt;- sum( v4 * u4 ) # Weighted average of the scalar products s &lt;- function(p) 3 * p^2 - 2 * p^3 p &lt;- s( x - i ) q &lt;- s( y - j ) b1 &lt;- (1-p)*a1 + p*a2 b2 &lt;- (1-p)*a3 + p*a4 (1-q) * b1 + q * b2 } xs &lt;- seq(from = 1, to = n, length = N+1)[-(N+1)] ys &lt;- seq(from = 1, to = m, length = M+1)[-(M+1)] return(outer( xs, ys, Vectorize(f) )) } Different parameters for the perlin noise will give us a higher a lower definition for our future DEM raster. Here we choose a trade off between an environment detailed enough for on a relatively wide area but small enough to be handled easily in memory. require(terra) require(sf) a &lt;- 0.6 k &lt;- 8 m &lt;- perlin_noise(2, 2, 2^k, 2^k) for ( i in 2:k ) m &lt;- m + a^i * perlin_noise(2^i, 2^i, 2^k, 2^k) plot(rast(m)) object.size(m) ## 524504 bytes To make it slightly more realistic we tweaked a bit the extremes, to create seas and mountains a bit closer to what a real DEM would look like. height &lt;- (m[,])*20 #height[height&lt;50]=0 height &lt;- height^3 height &lt;- height+abs(mean(height)) height[height&lt;min(height)*.25] &lt;- min(height)*.25 Visual the map as a simple 2D raster # height.ras &lt;- rast(height, extent=c(-3.5, 0.5, -0.5, 3.5), crs=&quot;+proj=latlon&quot;) height.ras &lt;- rast(&quot;data_original/east_narnia4x.tif&quot;) maxh &lt;- max(height.ras[], na.rm=T) col_ramp &lt;- colorRampPalette(c(&quot;#54843f&quot;, &quot;grey&quot;, &quot;white&quot;)) plot(height.ras^1.9, col=col_ramp(20), legend=F, reset=F) height.wat &lt;- height.ras height.wat[height.wat&gt;mean(height.wat[])] &lt;- NA plot(height.wat, col=&quot;lightblue&quot;, add=T, legend=F) If you really want to feel like being in a video game, you can play with rayshader, but its slow, tricky and you will probably loose a lot of time ¯\\_(ツ)_/¯ require(rayshader) height_map &lt;- raster_to_matrix(raster::raster(height)) hm_shade &lt;- sphere_shade(height_map, texture = &quot;imhof1&quot;, zscale=5) hm_ray &lt;- add_shadow(hm_shade, ray_shade(height_map, zscale = 19), 0.8) hm_ambiant &lt;- add_shadow(hm_ray, ambient_shade(height_map), 0,5) hm_lamb &lt;- add_shadow(hm_ambiant, lamb_shade(height_map), 0) plot_3d( hm_lamb,height_map, zscale = 10, fov = 0, theta = 20, zoom = .5, phi = 45, windowsize = c(1000, 800),water = TRUE, waterdepth = 0, wateralpha = 1, watercolor = &quot;lightblue&quot;, waterlinecolor = &quot;lightblue&quot;, waterlinealpha = .7, baseshape=&quot;hex&quot;) #HQ render, very slow #render_highquality( samples=256, clear = TRUE,light=TRUE) 2.3 Settlements position Given this new landscape we can now generate sites in specific locations (not on mountains, nor in water) with exponentially distributed size and make a network out of it. n &lt;- 20 # we will create 20 sites size &lt;- rexp(n) #assign a size for each site following an exponential distribution height.groups &lt;- height.ras # taking back the raster created before height.groups[height.groups&lt;mean(height.groups[])] &lt;- NA #replace values that are below mean level (under waer) height.groups[height.groups&lt;(maxh*.7)] &lt;- 1 # values below 70% of the maximum height are set as 1 height.groups[height.groups&gt;(maxh*.7)] &lt;- 200 # value above at 200 (high mountains) height.groups[is.na(height.groups)] &lt;- -1 # NA values (below waters) are set to -1 height.poly &lt;- as.polygons(height.groups) # convert height.groups as polygons that will be of three type: -1 =&gt; under water, 1, viable, and 200, high mountaines viable &lt;- makeValid(height.poly[2,]) # select polygon with &#39;1&#39; and make it a valid polygon as it may have some loop and problems The area where sites can potentially be generate looks like the green area on the map below plot(viable,col=adjustcolor(&quot;chartreuse&quot;,.8)) We can now use spatSample from package terra to randomly select 20 points on this viable polygon. sites &lt;- spatSample(viable, n) # generate n random points within the viable polygon and assign to variable sites plot(height.ras^1.9, col=col_ramp(50), legend=F, reset=F) plot(height.wat, col=&quot;lightblue&quot;, add=T, legend=F) plot(sites, cex=2, pch=21, add=T, bg=rainbow(length(sites), alpha=.6)) # get only the non submerged actual land and plot it above_level &lt;- height.ras &gt; mean(height.ras[]) coastline &lt;- st_as_sf(as.polygons(above_level))[2,] plot(coastline, col=NA, bgc=adjustcolor(&quot;cyan&quot;, 0.1), add=T) In the ontext of the archaeoriddle challenge files that describe this newly generated environment and the sites sampled on top of it needs to be produced. This can be done as: st_write(dsn=&quot;coastline2.shp&quot;, coastline) # Write the coastline as a shapefile writeRaster(filename=&quot;data_original/east_narnia4x.tif&quot;, height.ras, overwrite=T) #write the DEM as a raster 2.4 Network, Site Size And Climate – DEPRECATED The following steps were designed but never used. Create a network between sites library(igraph) crs(sites) &lt;- &quot;+proj=lonlat&quot; sites &lt;- sites[sample(nrow(sites), 20), ] ig &lt;- graph_from_adjacency_matrix( as.matrix(distance(sites)), weighted=T, mode=&quot;undirected&quot;) ig &lt;- set_graph_attr(ig, &quot;layout&quot;, crds(sites)) V(ig)$label &lt;- &quot;&quot; V(ig)$size &lt;- (size+1)*5 V(ig)$frame.color &lt;- &quot;black&quot; V(ig)$frame.width &lt;- .5 E(ig)$weight &lt;- 1/(E(ig)$weight^2) E(ig)$width &lt;- exp(E(ig)$weight)+.6 allcomu &lt;- cluster_louvain(ig)$memberships[1,] V(ig)$color &lt;- allcomu E(ig)$color &lt;- allcomu[head_of(ig,E(ig))] plot(height.ras^1.9, col=col_ramp(50), legend=F, reset=F) plot(height.wat, col=&quot;lightblue&quot;, add=T, legend=F) plot(ig, add=T, rescale=F, alpha=.2) Visualise sites on the 3D plot plot_3d( hm_lamb,height_map, zscale=20, fov=0, theta=20, zoom=1, phi=45, windowsize=c(1000, 800), water=TRUE, waterdepth=mean(height), wateralpha=1, watercolor=&quot;lightblue&quot;, waterlinecolor=&quot;lightblue&quot;, waterlinealpha=.7 ) render_points( extent=raster::extent(raster::raster(height.ras)), lat=2.13828, long=-1.685547, altitude=extract(height.ras,sites)[,1]+20, zscale=20, size=1, col=categorical_pal(max(allcomu))[allcomu], clear_previous=TRUE ) render_points( extent=raster::extent(raster::raster(height.ras)), lat=crds(sites)[,&quot;y&quot;], long=crds(sites)[,&quot;x&quot;], altitude=extract(height.ras, sites)[,1]+20, zscale=20, size=1, col=categorical_pal(max(allcomu))[allcomu], clear_previous=TRUE ) render_highquality(point_radius=5, samples=256, clear=TRUE, light=TRUE) let’s say the climate modulate site size in a naive way: for(i in seq(1, tstep, length.out=100)){ layout(matrix(1:2, nrow=2, ncol=1), heights=c(.8, .2)) par(mar=c(1, 2, 2, 1)) image(m, ann=F, axes=F, main=i) mtext(round(i), 3, 1) nsize &lt;- size*faketemp[i] + size + 1 points(crds(sites), bg=&quot;green&quot;, pch=21, cex=nsize) par(mar=c(2, 2, 0, 1)) plot( 1:tstep, faketemp, type=&quot;l&quot;, ylab=&quot;temp&quot;, xlab=&quot;time&quot;, ylim=range(faketemp), ann=F, frame.plot=F) points(i, faketemp[i], col=&quot;red&quot;, pch=20) } "],["population-growth-on-multiple-sites.html", "3 Population growth on multiple sites 3.1 Environmental resources Logistic decay 3.2 Initial sites and size: Initialize carrying capacity Create initial population matrix Initialize list of sites Run simulation Check sites touching Model fight with better probabilities Change population sizes Draw a war symbol where two clans are fighting", " 3 Population growth on multiple sites 3.1 Environmental resources We generate zones of high resources, that will attract settlements and support higher K. The resources will be located at given hotspots with an area around in which they decay with a logistic function. logisticdecayR Documentation Logistic decay Description Given a raster and a vector of points, set resources hotspots with a logistic decay around them Usage logisticdecay(pt, rast, L = 1, k = 1e-04, x0 = 60000) Arguments pt a vector points around witch decay is computed rast a raster to compute distances L starting point of decay k a vector of decay rates x0 areas around pt in which resources decay from Value Logistic decay vector Here’s the code for the generation of resources under logistic decay Show code Code ## Fucntion 13. Logistic decay for resource generation logisticdecay &lt;- function(pt, rast, L=1, k=0.0001, x0=60000){ ds &lt;- distance(rast, pt) logdec = L-L/(1+exp(-k*(ds-x0))) return(logdec) } ##ressource geolocalisation set manually goodresources &lt;- vect( cbind( x=c(-0.2300711, -3.1455282, -0.5086485, -1.9639755, -0.4077843, 0.019688, -3.116710), y=c(3.6423000, -0.2551019, -0.7440748, 1.1303214, 1.0248567, 0.2194895, 2.0267718) ) ) #spread of resources areas &lt;- 4 * c(100, 2000, 200, 300, 100, 200, 400) #speed of ressource decay: ks &lt;- c(0.0002, 0.0001000, 0.0001600, 0.0001800, 0.00040, .0002, 0.0002)/4 crs(goodresources) &lt;- crs(height.ras) allres &lt;- lapply( seq_along(goodresources), function(i){ logisticdecay(goodresources[i], mask(height.ras, viable), x=areas[i], k=ks[i] ) } ) ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= allna &lt;- sapply(allres, function(i)any(is.na(values(i)))) allres &lt;- allres[!allna] ress &lt;- allres[[1]] for(i in 2:length(allres)) ress &lt;- ress + allres[[i]] ress &lt;- mask(ress,viable) plot(ress) 3.2 Initial sites and size: We initialize the sites of 2 groups, HG and F. initKsR Documentation Initialize carrying capacity Description It generates a random carrying capacity for each site, but based on the amount of resources. Usage initKs( Kbase = c(HG = 30, F = 120), sites, ressources, sizeexp = NULL, rate = 0.5 ) Arguments Kbase baseline carrying capacity or different cultures sites raster with site and culture ressources a raster type for fall sites sizeexp Cultures for which to apply a random number generated by an exponential distribution that multiplies the amount of resources rate Rate of exponential distribution Value A list with a carrying capacity for each culture initpopstrucR Documentation Create initial population matrix Description This functions initializes a population matrix Usage initpopstruc(n = 100, ages = 10:30, p_sex = c(0.5, 0.5)) Arguments n number of individuals ages initial ages p_sex proportion individuals of different sex Value a dataframe with age and sex of every individual of the population initlistsitesR Documentation Initialize list of sites Description Initialize list of sites across the years of a simulation Usage initlistsites(list_sites, ts = 200) Arguments list_sites a list of population for all initial sites of the simulation ts length of simulation Value matrix of list sites ts &lt;- 250 #a manual way to set cultures given general geography cultures &lt;- rep(&quot;HG&quot;,length(sites)) cultures[(crds(sites)[,&quot;x&quot;] &lt; -1 &amp; crds(sites)[,&quot;y&quot;] &lt; 1)]=&quot;F&quot; sites$culture &lt;- cultures Kbase &lt;- c(&quot;HG&quot;=45,&quot;F&quot;=120) #difference in K for the two cultures # The initial Ks depends on the resources in the area sites$Ks &lt;- initKs(Kbase, sites, ress, sizeexp=&quot;F&quot;) #saveRDS(file=&quot;data_original/sitesinitialposition/&quot;, sites) # Optionally we can intialize here our list of sites and population structures # Otherwise, they are initialized within the run_simulation function # Population size at initialisation, a number close to Ks INs &lt;- round(runif(length(sites), 0.85, 0.95)*sites$Ks) # initialise population structure for all sites Ips &lt;- lapply(INs, initpopstruc) # Not we put the population structure across the years in a list Nts &lt;- initlistsites(Ips, ts=ts) You can see the code of initKs, initpopstruct and initlistsites functions here: Show code Code ## Function 14. Initial carrying capacity initKs &lt;- function(Kbase=c(&quot;HG&quot;=30,&quot;F&quot;=120), sites, ressources, sizeexp=NULL, rate=.5){ Ks &lt;- round(Kbase[sites$culture] + rnorm(length(sites), 0, 10)) while(any(Ks&lt;1)){ Ks &lt;- round( Kbase[sites$culture] + rnorm(length(sites), 0, 10) ) } #Ks[sites$culture==&quot;F&quot;]=Ks[sites$culture==&quot;F&quot;]*runif(sum(sites$culture==&quot;F&quot;),1,1) tmp &lt;- Ks * (1 + extract(ressources, sites)[, 2]) if(!is.null(sizeexp)){ tmp[sites$culture==sizeexp] &lt;- ( (Ks[sites$culture==sizeexp]) * (1 + rexp(sum(sites$culture==sizeexp), rate=rate) * extract(ressources, sites[sites$culture==sizeexp])[,2]) ) } tmp } ## Function 15. Create population matrix initpopstruc &lt;- function(n=100, ages=10:30, p_sex=c(0.5, 0.5)){ initpop = data.frame( &quot;Age&quot; = sample(ages, n, ages, replace = TRUE), &quot;Sex&quot; = sample(c(&quot;M&quot;, &quot;F&quot;), n, prob = p_sex, replace = TRUE)) return(initpop) } ## Function 16. Initialize initial list of sites initlistsites &lt;- function(list_sites, ts=200){ Nts &lt;- matrix(0, nrow=ts+1, ncol=length(list_sites)) Nts[1,] &lt;- sapply(list_sites, nrow) return(Nts) } Now we have sites with two cultures, initialise the parameters we will use: #(read sites saved before) # sites=readRDS(file=&quot;data_original/sitesinitialposition/&quot;,sites) #initialisation ts &lt;- 250 # Kbase=c(&quot;HG&quot;=45,&quot;F&quot;=120) #difference in K for the two cultures # spatial penality to extent: lower, bigger penality cul_ext &lt;- c(&quot;HG&quot;=7, &quot;F&quot;=6) # penality of occupational area: low, other sites can come close penal_cul &lt;- c(&quot;HG&quot;=4, &quot;F&quot;=5) # proba to give birth every year prob_birth &lt;- c(&quot;HG&quot;=0.3, &quot;F&quot;=0.5) # proba to die when pop &gt; K prob_survive &lt;- c(&quot;HG&quot;=0.8, &quot;F&quot;=0.6) # proba to create new settlement when Ne &gt; K prob_split &lt;- c(&quot;HG&quot;=0.2, &quot;F&quot;=0.6) # how big the group of migrant should be to create a new city vs # migrate to a existing one minimals &lt;- c(&quot;HG&quot;=0.14, &quot;F&quot;=0.20) # prob to migrate to existing settlement when Ne &gt; K prob_move &lt;- c(&quot;HG&quot;=0.2,&quot;F&quot;=0.1) Let’s create again our raster map from the height.ras from the previous chapter height.wat &lt;- height.ras height.wat[height.wat&gt;mean(height.wat[])] &lt;- NA height.groups &lt;- height.ras maxh &lt;- max(height.ras[],na.rm=T) height.groups[height.groups&lt;mean(height.groups[])] &lt;- NA height.groups[height.groups&lt;(maxh*.7)] &lt;- 1 height.groups[height.groups&gt;(maxh*.7)] &lt;- 200 height.groups[is.na(height.groups)] &lt;- -1 height.poly &lt;- as.polygons(height.groups) viable &lt;- makeValid(height.poly[2,]) plotMap(height.ras,height.wat,paste0(&quot;year &quot;, 0)) plot(sites, pch=21, add=T, bg=rainbow(2, alpha=0.6)[as.factor(sites$culture)]) text(sites) The run_simulation function will take the raster data and parameters for the different populations and run for the specified number of years. run_simulationR Documentation Run simulation Description This function runs a stochastic simulation in which different cultures positioned in sites in a raster interact, grow, die, fight, migrate,... Usage run_simulation( cultures = NULL, viable = viable, sites = sites, dem = height.ras, ressources = ress, water = height.wat, foldervid = \"pathtofinal\", visu = FALSE, visumin = TRUE, ts = 20000, Kbase = c(HG = 35, F = 120), cul_ext = c(HG = 7, F = 6), penal_cul = c(HG = 4, F = 5), prob_birth = c(HG = 0.3, F = 0.5), prob_survive = c(HG = 0.8, F = 0.6), prob_split = c(HG = 0.2, F = 0.6), prob_move = c(HG = 0.2, F = 0.1), minimals = c(HG = 0.14, F = 0.2), bufferatack = 400, buffersettl = 2000, Nts = NULL, Ips = NULL ) Arguments cultures Vector of cultures to be simulated. Default is NULL, in which case it is taken from sites. Culture names must also be present in as names in the named vectors with the simulation parameters for each culture. viable Viable SpatVector of the territory sites SpatVector of sites dem Digital Elevation Model SpatRaster of the map ressources SpatVector with resources position water SpatRaster with water foldervid If visu=TRUE, folder to save plots with simulation snaps visu logical; whether to plot simulation snaps visumin logical; whether to plot a minimal visualization of the simulation ts Length of the simulation in years Kbase Named vector with carrying capacities for the cultures cul_ext Named vector. Spatial penalty to extent: lower, bigger penality penal_cul Named vector. Penality of occupational area: if low, other sites can come close prob_birth Named vector. Probability of giving birth every year prob_survive Named vector. Probability of dying when the pop size is greater than the carrying capacity prob_split Named vector. Probability of creating a new split settlement when the pop size is greater than the carrying capacity prob_move Probability of migrating to a existing settlement when Ne &gt; K minimals Named vector. How big, proportionally, the group of migrants should be to create a new city vs migrate to a existing one. bufferatack Maximum distance around which a settlement can fight buffersettl Minimum distance around a site in which a new settlement cannnot settle Nts Initiallized list of sites. Created with initlistsites. Default is NULL, in which case it's created inside the function from sites. Ips Initial population structure. Created with initpopstruc. Default is NULL, in which case it's created inside the function from sites Value A list with site data across the simulation period, population structures, war casualties and updated sites positions. It uses a number of other functions to model contacts between sites, the outcomes of fights and migrations whotouchR Documentation Check sites touching Description Check who's touching a given site Usage whotouch(i, sites, Ne, homophily = F, buffersize = 200) Arguments i Index of the site checked sites Raster with site coordinates, cultures and carrying capacities Ne population size of all sites homophily if true, return all sites that touch (even same culture) buffersize Buffer size around a given site to consider contacts. It's a factor that multiplies the population size Ne Value Returns a raster with the sites that are touching site i fightbetterlossR Documentation Model fight with better probabilities Description A function to compute lost during a fighting. The winner and looser are decided probabilistically from their relative size. It then uses a binomial to model the loss of population sizes, with probability based on their relative sizes. Usage fightbetterloss(Ne, a, b) Arguments Ne list of population sizes for the fighting settlement a indice of the first settlement b indice of the second settlement Value Returns the updated population size of both settlements engaged in the fight changePopSizeR Documentation Change population sizes Description It changes population sizes due to killing or swap between a loosing and winning population Usage changePopSize( loosingPop, size, winingPop = NULL, new = F, method = \"random\", probs = dnorm, prob.option = list(sd = 10, mean = 22) ) Arguments loosingPop data.frame of the population that's decreasing size Number of deaths or size of the population swap winingPop data.frame of the population that's increasing new Deprecated method Currently only supports &quot;random&quot; probs Density distribution function to calculate probabilities of individuals to be sampled based on age prob.option Options for probs functions (e.g. mean and sd for dnorm) Value Either the updated loosing population data.frame or a list with both the winning and loosing populations warpointsR Documentation Draw a war symbol where two clans are fighting Description Draws a war symbol in the sites raster at the point of intersection between fighting clans Usage warpoints(sites, a, b, Ne, buffersize = 300, plot = T, sizewar = 2) Arguments sites Raster with site coordinates, cultures and carrying capacities a Index of first settlement b Index of second settlement Ne Population sizes list buffersize buffer size around a given site to consider contacts. It's a factor that multiplies the population size Ne plot Whether to make a plot or not sizewar Size of the war symbol Value Raster of the intersection point between sites a and b, if any. Or we can run a simple simulations using the saved elevation data. height.ras &lt;- rast(&quot;data_original/east_narnia4x.tif&quot;) height.wat &lt;- height.ras height.wat[height.wat&gt;mean(height.wat[])] &lt;- NA height.groups &lt;- height.ras maxh &lt;- max(height.ras[],na.rm=T) height.groups[height.groups&lt;mean(height.groups[])] &lt;- NA height.groups[height.groups&lt;(maxh*.7)] &lt;- 1 height.groups[height.groups&gt;(maxh*.7)] &lt;- 200 height.groups[is.na(height.groups)] &lt;- -1 height.poly &lt;- as.polygons(height.groups) viable &lt;- makeValid(height.poly[2,]) sites &lt;- vect(&quot;data_original/sitesinitialposition/&quot;) ts &lt;- 10 print(paste0(&quot;Starting simulation &quot;,&quot;nan&quot;)) ## [1] &quot;Starting simulation nan&quot; onesimu &lt;- run_simulation( sites=sites, viable=viable, dem=height.ras, ressources=rast(&quot;data_original/resources.tiff&quot;), water=height.wat, foldervid=&quot;nan&quot;, visu=F, visumin=F, ts=ts, #length of simulation in year Kbase=c(&quot;HG&quot;=35, &quot;F&quot;=110), #difference in K for the two cultures cul_ext=c(&quot;HG&quot;=7, &quot;F&quot;=6), #spatial penality to extent: lower, bigger penality penal_cul=c(&quot;HG&quot;=4, &quot;F&quot;=5), #penality of occupational area: low, other sites can cam close prob_birth=c(&quot;HG&quot;=0.3, &quot;F&quot;=0.5), #proba of giving birth every year prob_survive=c(&quot;HG&quot;=0.8, &quot;F&quot;=0.65), #proba of dying when pop &gt; K prob_split=c(&quot;HG&quot;=0.5, &quot;F&quot;=0.6), #proba of creating a new settlement when Ne &gt; K minimals=c(&quot;HG&quot;=0.14,&quot;F&quot;=0.20), #how big the group of migrant should be to create a new city vs migrate to a existing one bufferatack=300, #distance max around which settlement can fight prob_move=c(&quot;HG&quot;=0.2, &quot;F&quot;=0.1) #proba of migrating to existing settlement when Ne &gt; K ) ## [1] &quot;year 2 total 1581 with 30 sites ( F:4,HG:26 )&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;6 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;6 migrant from HG to HG&quot; ## [1] &quot;year 3 total 1752 with 30 sites ( F:4,HG:26 )&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 38 and pop 6&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 48 and pop 7&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;4 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 31 and pop 7&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;7 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;9 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;5 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;6 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;3 migrant from HG to HG&quot; ## [1] &quot;year 4 total 1812 with 33 sites ( F:4,HG:29 )&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;6 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;30 migrant from F to F&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 43 and pop 7&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 31 and pop 8&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 41 and pop 9&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;17 migrant from F to F&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;4 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 23 and pop 5&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 54 and pop 11&quot; ## [1] &quot;year 5 total 1869 with 38 sites ( F:4,HG:34 )&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 43 and pop 4&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (F) of K 134 and pop 38&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 31 and pop 5&quot; ## [1] &quot;year 6 total 1930 with 41 sites ( F:5,HG:36 )&quot; ## [1] &quot;year 7 total 1959 with 41 sites ( F:5,HG:36 )&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 42 and pop 7&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;14 migrant from F to F&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 20 and pop 7&quot; ## [1] &quot;year 8 total 2006 with 43 sites ( F:5,HG:38 )&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 26 and pop 9&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;25 migrant from F to F&quot; ## [1] &quot;year 9 total 2057 with 44 sites ( F:5,HG:39 )&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;6 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 43 and pop 6&quot; ## [1] &quot;year 10 total 2074 with 45 sites ( F:5,HG:40 )&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;4 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;4 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;5 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;7 migrant from HG to HG&quot; ## |---------|---------|---------|---------| ========================================= [1] &quot;5 migrant from HG to HG&quot; ## [1] &quot;year 11 total 2074 with 45 sites ( F:5,HG:40 )&quot; ## |---------|---------|---------|---------| ========================================= |---------|---------|---------|---------| ========================================= [1] &quot;new settlement (HG) of K 42 and pop 6&quot; Check the code of the simulation functions here: Show code Code ## Function 17. Change population sizes changePopSize &lt;- function(loosingPop, size, winingPop=NULL, new=F, method=&quot;random&quot;, probs=dnorm, prob.option=list(&quot;sd&quot;=10, &quot;mean&quot;=22)) { #print(dim(loosingPop)) #if(!is.null(winingPop)) # print(dim(winingPop)) #if(length(size)==0 || size==0)return(data.frame(Age=numeric(),Sex=character())) if(nrow(loosingPop)==0){ kill &lt;- 0 }else if(method==&quot;random&quot;){ kill &lt;- tryCatch( sample(x=1:nrow(loosingPop), size=size, prob=probs(loosingPop$Age, mean=prob.option$mean, sd=prob.option$sd)), error=function(e){ print(paste0(&quot;problem with population replacement for settlement of size:&quot;, nrow(loosingPop), &quot; need to loose &quot;, size));0 } ) } #print(paste(&quot;diff&quot;,nrow(popdistrib)-size,&quot;new&quot;,size)) if(!is.null(winingPop)){ winingPop &lt;- rbind(winingPop, loosingPop[kill,]) } loosingPop &lt;- loosingPop[-kill,] if(!is.null(winingPop)) return(list(loosingPop, winingPop)) else return(loosingPop) } ## Function 18. Check sites touching whotouch &lt;- function(i, sites, Ne, homophily=F, buffersize=200){ touch &lt;- st_intersects( st_make_valid(st_as_sf(buffer(sites[i], Ne[i] * buffersize))), st_make_valid(st_as_sf(buffer(sites, Ne * buffersize)))) if( length(touch) &gt; 0 ){ enemies &lt;- unlist(touch) if(homophily){ enemies &lt;- enemies[enemies != i] } else { enemies &lt;- enemies[sites$culture[enemies] != sites$culture[i]] } } else { enemies &lt;- NA } return(enemies) } ## Function 19. Model a simple fight simplefight &lt;- function(Ne, a, b){ if(runif(1) &lt; Ne[a] / (Ne[a] + Ne[b])){ v &lt;- a l &lt;- b } else{ v &lt;- b l &lt;- a } # Keep the original pop sizes for reporting outcome one &lt;- Ne # Update population sizes using a binomial Ne[v] &lt;- rbinom(n=1, prob=0.9, size=Ne[v]) Ne[l] &lt;- rbinom(n=1, prob=0.4, size=Ne[l]) print( paste(&quot;victory&quot;, v, &quot;(&quot;, one[v], &quot;-&quot;, Ne[v],&quot;) over&quot;, l, &quot;(&quot;,one[l],&quot;-&quot;,Ne[l],&quot;), total of: &quot;, (one[v]-Ne[v]) + (one[l]-Ne[l]), &quot;people&quot;)) return(Ne) } ## Function 20. Model fight with better probabilities fightbetterloss &lt;- function(Ne,a,b){ if( runif(1) &lt; Ne[a]/(Ne[a] + Ne[b]) ){ v &lt;- a l &lt;- b } else{ v &lt;- b l &lt;- a } one &lt;- Ne Ne[v] &lt;- rbinom(n=1, prob=1 - Ne[l]/(Ne[v] + Ne[l]), size=Ne[v]) Ne[l] &lt;- rbinom(n=1, prob=1 - Ne[v]/(Ne[v] + Ne[l]), size=Ne[l]) print(paste0(&quot;victory &quot;, v, &quot;(&quot;, one[v], &quot;-&quot;, Ne[v],&quot;) over &quot;, l, &quot; (&quot;, one[l], &quot;-&quot;, Ne[l], &quot;), tot: &quot;, (one[v]-Ne[v]) + (one[l]-Ne[l]), &quot;losses&quot;)) return(Ne) } ## Function 21. Draw a war symbol where two clans are fighting warpoints &lt;- function(sites, a, b, Ne, buffersize=300, plot=T, sizewar=2){ meetpoints &lt;- crop( buffer(sites[a], 1+Ne[a] * buffersize), buffer(sites[b], 1+Ne[b] * buffersize) ) if( length(meetpoints)&gt;0 ){ p &lt;- spatSample(meetpoints, 1) if(plot &amp; length(p)&gt;0){ plot(p, add=T, bg=&quot;red&quot;, pch=&quot;🔥&quot;, cex=sizewar, col=adjustcolor(&quot;yellow&quot;, 0.1)) plot(p, add=T, bg=&quot;yellow&quot;, pch=&quot;⚔️&quot; ,cex=sizewar) } return(p) } else return(NULL) } ## Function 22. Run simulation run_simulation &lt;- function(cultures=NULL, viable=viable, sites=sites, dem=height.ras, ressources=ress, water=height.wat, foldervid=&quot;pathtofinal&quot;, visu=FALSE, visumin=TRUE, ts=20000, Kbase=c(&quot;HG&quot;=35, &quot;F&quot;=120), cul_ext=c(&quot;HG&quot;=7, &quot;F&quot;=6), penal_cul=c(&quot;HG&quot;=4, &quot;F&quot;=5), prob_birth=c(&quot;HG&quot;=0.3, &quot;F&quot;=0.5), prob_survive=c(&quot;HG&quot;=0.8, &quot;F&quot;=0.6), prob_split=c(&quot;HG&quot;= .2, &quot;F&quot;=0.6), prob_move=c(&quot;HG&quot;=0.2, &quot;F&quot;=0.1), minimals=c(&quot;HG&quot;=.14, &quot;F&quot;=.20), bufferatack=400, buffersettl=2000, Nts=NULL, Ips=NULL ){ ## Run stochastic process Ks &lt;- sites$Ks cultures &lt;- sites$culture if(is.null(Nts)){ INs &lt;- round(runif(length(sites), 0.85, 0.95) * sites$Ks) #Population size at initialisation Ips &lt;- lapply(INs, initpopstruc) #initialise population structure for all sites Nts &lt;- initlistsites(Ips, ts=ts) frame &lt;- 0 mint &lt;- 2 } else {##should check and test howto start back a simulation mint &lt;- nrow(Nts) frame &lt;- nrow(Nts) } ### visualisation ===== if(!dir.exists(foldervid) &amp; visu){ dir.create(foldervid) } ### warcasualties &lt;- vector(&quot;integer&quot;, ts) for (i in 2:(ts+1)){ countcult &lt;- table(sites$culture[Nts[i-1, ] &gt; 0]) if ( length(countcult) != 2 ) { return( list(Nts=Nts[,1:i], warcasualties=warcasualties[1:i], Ips=Ips, sites=sites ) ) } print( paste(&quot;year&quot;, i, &quot;total&quot;, sum(sapply(Ips,nrow)), &quot;with&quot;, length(sites), &quot;sites (&quot;, paste0(paste(names(countcult), countcult, sep=&quot;:&quot;), collapse=&quot;,&quot;), &quot;)&quot;)) if (visumin){ ### visualisation ===== frame &lt;- frame+1 filename &lt;- sprintf(&quot;map_%06d.png&quot;, frame) png(file.path(foldervid,filename), width=800, height=800, pointsize=20) plotMap(dem, water, paste0(&quot;year &quot;,i)) ######## } inactives &lt;- (Nts[i-1,]==0) for ( s in sample(seq_along(sites)[!inactives]) ){ if ( visu ) { ### visualisation ===== frame &lt;- frame+1 filename &lt;- sprintf(&quot;map_%08d.png&quot;, frame) png(file.path(foldervid,filename), width=800, height=800, pointsize=20) plotMap(dem,water,paste0(&quot;year &quot;, i)) ######## } city &lt;- NULL Ips[[s]] &lt;- Gpd( #compute new population for the sites Ips[[s]], K = Ks[[s]], p_offspring = prob_birth[sites$culture[s]], prob = prob_survive[sites$culture[s]] ) newN &lt;- nrow(Ips[[s]]) #count population size if(newN &gt;= (Ks[[s]])){ #if new population is more than carrying capacity: migration scenario migrants &lt;- newN - round(Ks[[s]]*0.9) ##Creation of new city new_site &lt;- NULL #if(sites$culture[s]==&quot;F&quot;)print(paste(&quot;possib&quot;,migrants, (minimals[sites$culture[s]]*sites$Ks[s]))) tmp &lt;- Nts[i-1,] tmp[Nts[i,] &gt; 0] &lt;- Nts[i, Nts[i,] &gt; 0] #tmp=tmp+sqrt(sites$Ks) havemoved &lt;- F if (migrants &gt;= (minimals[sites$culture[s]]*sites$Ks[s]) &amp; runif(1)&lt;prob_split[sites$culture[s]] ){ #if supopulation &gt; 10 people, 10% chance of creation of a new city #print(paste(&quot;look for new spot for &quot;,migrants, &quot;from site&quot;,s,&quot;culture&quot;,sites$culture[s])) #mean of area of influence infarea &lt;- (sqrt(tmp)+penal_cul[cultures]) * buffersettl buffersize &lt;- rnorm(length(infarea), infarea, infarea * 0.1) buffersize[tmp==0] &lt;- 0 territory &lt;- erase(viable, buffer(sites, buffersize)) if( length(territory)&gt;0 ){ #print(paste(&quot;found new spot&quot;,migrants)) ##select a new site given its distance to the old one and the ressourcesource available in ressources d2 &lt;- logisticdecay( sites[s], dem, x=20000*cul_ext[sites$culture[s]] ) w &lt;- (0.7 * d2 + 0.3*ressources) / (0.7*minmax(d2)[2] + 0.3*minmax(ressources)[2]) new_site &lt;- spatSample( x=mask( w * logisticdecay(sites[s], dem, k=0.00002, x=20000*cul_ext[sites$culture[s]]), territory), size=1, method=&quot;weights&quot;, xy=T)[1:2] new_site &lt;- vect(new_site, geom=c(&quot;x&quot;,&quot;y&quot;)) if ( length(new_site)&gt;0 &amp; all(!is.na(crds(new_site))) ){ ##add new site to site listes ##initialise population struc of new site #print(paste(&quot;total sites:&quot;,length(Ips))) #print(paste(&quot;dim Nts:&quot;,dim(Nts)[2])) #print(paste(&quot;site sf Nts:&quot;,length(sites))) Ips[[length(Ips)+1]] &lt;- initpopstruc(n=migrants) #initialise a fake populaition, will be updated by real migrants later new_site$culture &lt;- sites$culture[s] new_site$Ks &lt;- round(initKs( Kbase, sites=new_site, ressources, sizeex=&quot;F&quot;, rate=0.45)) print(paste0(&quot;new settlement (&quot;, sites$culture[s], &quot;) of K &quot;, new_site$Ks, &quot; and pop &quot;, migrants)) sites &lt;- rbind(sites, new_site) Ks[length(Ks)+1] &lt;- new_site$Ks city &lt;- length(Ips) Nts &lt;- cbind(Nts, rep(0,ts+1)) Nts[i, city] &lt;- migrants cultures &lt;- c(cultures, cultures[s]) #print(paste(&quot;new site sf Nts:&quot;,length(sites))) #print(paste(&quot;new dim Nts:&quot;,dim(Nts)[2])) #print(paste(&quot;new total sites:&quot;,length(Ips))) havemoved &lt;- T } } } ## if no creation of new city happen, there is a certain probability that people will move if( length(new_site)==0 &amp;&amp; runif(1) &lt; prob_move[sites$culture[s]] ){ #getj att &lt;- extract(ressources,sites)[,2] space &lt;- sites$Ks - (Nts[i-1,] + migrants) dis &lt;- extract(logisticdecay(sites[s], dem, k=0.00002, x=1), sites)[,2] attractivity &lt;- att * space * dis #attractivity=attractivity*(1+10*(sites$culture[s]==sites$culture)) #4 times more likely to go to similar culture attractivity[s] &lt;- min(attractivity)-1 attractivity &lt;- exp(attractivity)/sum(exp(attractivity)) attractivity[Nts[i-1,]&lt;10] &lt;- 0 attractivity[sites$culture!=sites$culture[s]] &lt;- 0 if(any(is.na(attractivity))){ print(attractivity) attractivity[is.na(attractivity)] &lt;- 0 } city &lt;- sample(size=1, x=seq_along(sites), prob=attractivity) Nts[i,city] &lt;- Nts[i-1,city] + migrants print(paste(migrants, &quot;migrant from&quot;, sites$culture[s], &quot;to&quot;, sites$culture[city])) havemoved &lt;- T } if( havemoved ){ #print(paste(&quot;old spot&quot;,migrants,&quot; for &quot;,nrow(Ips[[s]]))) #print(paste(&quot;old new spot&quot;,migrants,&quot; for &quot;,nrow(Ips[[city]]))) #if(city&gt;length(Ips))print(paste(&quot;problem, migrants:&quot;,migrants)) #print(paste(&quot;the other:&quot;,city)) Ips[c(s,city)] &lt;- changePopSize( loosingPop=Ips[[s]], winingPop=Ips[[city]], size=migrants ) newN &lt;- newN - migrants #print(paste(&quot;loosing &quot;,newN,&quot; vs &quot;,nrow(Ips[[s]]))) #print(paste(&quot;wining &quot;,newN,&quot; vs &quot;,nrow(Ips[[city]]))) } } Nts[i,s] &lt;- newN if (visu){ ###visualisation========= sitescols &lt;- rep(1,length(sites)) siteslwd &lt;- rep(1,length(sites)) ii=NULL if(!is.null(city)){ sitescols[s] &lt;- &quot;yellow&quot; sitescols[city] &lt;- &quot;red&quot; siteslwd[s] &lt;- 3 siteslwd[city] &lt;- 3 ii &lt;- st_cast(st_combine(st_as_sf(sites[c(s, city)])), &quot;LINESTRING&quot;) } if (!is.null(ii)){ plot(ii ,add=T) } tmp &lt;- Nts[i-1,] tmp[Nts[i,]&gt;0] &lt;- Nts[i,Nts[i,]&gt;0] plot(sites, cex=(as.integer(Nts[i,]&gt;0) * 0.3 + Nts[i,]/200), pch=21, add=T, bg=rainbow(2, alpha=0.6)[as.factor(sites$culture)], lwd=siteslwd, col=sitescols) dev.off() ###======================= } } if(visumin){ plot(sites, cex=(as.integer(Nts[i,]&gt;0) * 0.3 + Nts[i,]/200), pch=21, add=T, bg=rainbow(2, alpha=0.6)[as.factor(sites$culture)]) } potentialfighters &lt;- which(sites$culture==&quot;F&quot; &amp; Nts[i,]&gt;50) for (s in sample(x=potentialfighters, size=round(length(potentialfighters)*0.1))){ buff &lt;- bufferatack potentialvictims &lt;- which(sites$culture !=sites$culture[s] &amp; Nts[i,]&gt;0) clash &lt;- whotouch(s, sites, Ne=Nts[i,], buffersize=buff) if(length(clash)&gt;0 &amp;&amp; !is.na(clash)){ if(length(clash) == 1){ attack &lt;- clash } else { attack &lt;- sample(clash, 1) } newns &lt;- fightbetterloss(Ne=Nts[i,], a=s, b=attack) casualties &lt;- sum(Nts[i, c(s,attack)] - newns[c(s,attack)]) warcasualties[i] &lt;- casualties sizew &lt;- casualties^2/4000 warpoints(sites, s, attack, Ne=Nts[i,], buffersize=buff, sizewar=sizew+0.5) #effectively kill people in population (should be done taking into account age pyramid to be more realistic) Ips[[s]] &lt;- changePopSize(loosingPop=Ips[[s]], size=(Nts[i,s] - newns[s])) Ips[[attack]] &lt;- changePopSize(loosingPop=Ips[[attack]], size=(Nts[i, attack] - newns[attack])) Nts[i,] &lt;- newns print(paste0(&quot;fight : #&quot;, s, &quot; (&quot;, cultures[s], &quot;) left with &quot;, Nts[i,s], &quot; (bef:&quot;, Nts[i-1,s], &quot;) ind., attacked: #&quot;, attack, &quot; (&quot;, cultures[attack], &quot;) left with &quot;, Nts[i,attack], &quot; (bef:&quot;, Nts[i-1,attack],&quot;) ind., #death=&quot;,casualties)) } } if(visumin){ dev.off() } } return(list(Nts=Nts, warcasualties=warcasualties, Ips=Ips, sites=sites)) } The list onesimu contains a few interesting info: Nts &lt;- onesimu$Nts # population at each timestep warcasualties &lt;- onesimu$warcasualties #death by war at each time step Use ressource to adjust the Ks: plot(sites, cex=(1+Nts[1,]/100), pch=21, bg=rainbow(2, alpha=0.6)[as.factor(sites$culture)]) We look at the simulation step by stepk Step by step to allow interaction between sites: ## Run stochastic process #par(mfrow=c(2,1)) i &lt;- ncol(Nts) plot(1, 1, type=&quot;n&quot;, xlim=c(0,i), ylim=c(0,max(Nts)), xlab=&quot;time&quot;, ylab=&quot;popsize&quot;) lapply(1:ncol(Nts), function(j)lines(Nts[,j],col=rainbow(2)[as.factor(sites$culture)[j]]) ) ## [[1]] ## NULL ## ## [[2]] ## NULL ## ## [[3]] ## NULL ## ## [[4]] ## NULL ## ## [[5]] ## NULL ## ## [[6]] ## NULL ## ## [[7]] ## NULL ## ## [[8]] ## NULL ## ## [[9]] ## NULL ## ## [[10]] ## NULL ## ## [[11]] ## NULL ## ## [[12]] ## NULL ## ## [[13]] ## NULL ## ## [[14]] ## NULL ## ## [[15]] ## NULL ## ## [[16]] ## NULL ## ## [[17]] ## NULL ## ## [[18]] ## NULL ## ## [[19]] ## NULL ## ## [[20]] ## NULL ## ## [[21]] ## NULL ## ## [[22]] ## NULL ## ## [[23]] ## NULL ## ## [[24]] ## NULL ## ## [[25]] ## NULL ## ## [[26]] ## NULL ## ## [[27]] ## NULL ## ## [[28]] ## NULL ## ## [[29]] ## NULL ## ## [[30]] ## NULL ## ## [[31]] ## NULL ## ## [[32]] ## NULL ## ## [[33]] ## NULL ## ## [[34]] ## NULL ## ## [[35]] ## NULL ## ## [[36]] ## NULL ## ## [[37]] ## NULL ## ## [[38]] ## NULL ## ## [[39]] ## NULL ## ## [[40]] ## NULL ## ## [[41]] ## NULL ## ## [[42]] ## NULL ## ## [[43]] ## NULL ## ## [[44]] ## NULL ## ## [[45]] ## NULL ## ## [[46]] ## NULL Visualise, Record deposit and loss. for the 5 first sites (see next chapters for A_rates). alldeposit &lt;- lapply( 1:5, function(i){ Rec_c(sapply(Nts[,i], A_rates), InitBP = 15000, ts=ts, r=0.2, max_bone_thickness=&quot;m&quot;) } ) maxy &lt;- max(sapply(alldeposit, function(i)max(apply(i,2,sum)))) nill &lt;- lapply(alldeposit, function(depo)barplot(t(depo), col=viridis(ts+1), ylim=c(0,maxy))) Population by time and culture par(mfrow=c(2,1)) plot(1, 1, type=&quot;n&quot;, xlim=c(0,i), ylim=c(0,max(Nts)), xlab=&quot;time&quot;, ylab=&quot;popsize&quot;) lapply(1:ncol(Nts), function(i)lines(Nts[,i], col=rainbow(2)[as.factor(sites$culture)[i]])) ## [[1]] ## NULL ## ## [[2]] ## NULL ## ## [[3]] ## NULL ## ## [[4]] ## NULL ## ## [[5]] ## NULL ## ## [[6]] ## NULL ## ## [[7]] ## NULL ## ## [[8]] ## NULL ## ## [[9]] ## NULL ## ## [[10]] ## NULL ## ## [[11]] ## NULL ## ## [[12]] ## NULL ## ## [[13]] ## NULL ## ## [[14]] ## NULL ## ## [[15]] ## NULL ## ## [[16]] ## NULL ## ## [[17]] ## NULL ## ## [[18]] ## NULL ## ## [[19]] ## NULL ## ## [[20]] ## NULL ## ## [[21]] ## NULL ## ## [[22]] ## NULL ## ## [[23]] ## NULL ## ## [[24]] ## NULL ## ## [[25]] ## NULL ## ## [[26]] ## NULL ## ## [[27]] ## NULL ## ## [[28]] ## NULL ## ## [[29]] ## NULL ## ## [[30]] ## NULL ## ## [[31]] ## NULL ## ## [[32]] ## NULL ## ## [[33]] ## NULL ## ## [[34]] ## NULL ## ## [[35]] ## NULL ## ## [[36]] ## NULL ## ## [[37]] ## NULL ## ## [[38]] ## NULL ## ## [[39]] ## NULL ## ## [[40]] ## NULL ## ## [[41]] ## NULL ## ## [[42]] ## NULL ## ## [[43]] ## NULL ## ## [[44]] ## NULL ## ## [[45]] ## NULL ## ## [[46]] ## NULL plot(apply(Nts, 1, sum)[1:i], xlab=&quot;time&quot;, ylab=&quot;popsize&quot;) Below some useful code to manually select the resource origins on the map (by clicking on the screen) and explore different decays around them plotMap(height.ras, height.wat, paste0(&quot;year &quot;, 0)) new_site &lt;- vect(as.data.frame(locator()), geom=c(&quot;x&quot;, &quot;y&quot;)) # select point on the sscreep crs(new_site) &lt;- crs(height.ras) d2 &lt;- logisticdecay(new_site, height.ras, x=20000) # generate a logistic decay around the point plot(d2) w &lt;- (0.7*d2 + 0.3*ress) / (0.7*minmax(d2)[2] + 0.3*minmax(ress)[2]) plot(w) plot(mask(w*logisticdecay(new_site, height.ras, k=0.00002, x=1), territory)) multisamp &lt;- sapply( 1:1000, function(i){ spatSample(x=w, size=1, method=&quot;weights&quot;, xy=T)[1:2] } ) Exploring some trajectories of the simulations i &lt;- nrow(Nts) plot(apply(Nts[1:i, sites$culture==&quot;F&quot;], 1, sum), col=&quot;red&quot;, type=&quot;l&quot;, lwd=2, ylim=c(0, max(apply(Nts, 1, sum)))) points(apply(Nts[1:i, sites$culture==&quot;HG&quot;], 1, sum), col=&quot;blue&quot;, lwd=2, type=&quot;l&quot;) plot(warcasualties[1:(i-1)], lwd=2, col=&quot;green&quot;, type=&quot;h&quot;, yaxt=&quot;n&quot;, ylab=&quot;&quot;) axis(4) par(new=T) growF &lt;- apply(Nts[1:(i-1), sites$culture==&quot;F&quot;], 1, sum) growHG &lt;- apply(Nts[1:(i-1), sites$culture==&quot;HG&quot;], 1, sum) plot(growF, col=&quot;red&quot;, type=&quot;l&quot;, lwd=2, ylim=c(0, max(growF, growHG))) points(growHG, col=&quot;blue&quot;, lwd=2, type=&quot;l&quot;) "],["record-formation.html", "4 Record formation 4.1 Theoretical model 4.2 Implementation Generation of population dynamics Simulation of death process Simulation of carrying capacity limitation Stochastic population generation Simulate anthropogenic deposition Depth protocol deposition Archaeological deposition record 4.3 Example and simulation", " 4 Record formation 4.1 Theoretical model We have produced a computational model, replicating the process of formation of the archaeological record in a specific site, accounting for different variables. In order to consider the possible relation between those variables, we have decided to express them as a Directed Acyclic Graph (DAG), following the ECS-DAG methodology proposed by Ferguson et al. (2020). In this case, however, and because our goal is to obtain an accurate initial template for the development of the model, we have not considered setting an exposure variable, but rather to propose different theoretical directional and causal relationships without relying on the conventional exposure-outcome assessment. Therefore, highlights in the graph below do not intend to differentiate among confounders, mediators, etc., but to emphasize the possible weight that each variable has for producing the outcome (produced waste by \\(m^2\\)). The above graph depicts a very schematic way to represent the formation of the archaeological record (\\(W/m^2\\)). In this case, we are interested in radiocarbon dating, focusing on bone samples; that is the number (and range) of potential 14C dates produced in a site, and this is key to understand the way in which we produced the model. We are aware that generating a specific archaeological palimpsest depends on a large quantity of variables, some of which may be controlled by field archaeologists and some of which may not (or are not). Therefore, the graph above must be read as follows. Asides from the outcome variable, the exposure variables, Pop (group size), Anthropogenic deposition rates and Natural deposition rates (depicted in orange), are designed in a way that they can be activated for the model to infer them, they can be provided by the archaeologist, or they can be simply ignored. In the most elementary case, the archaeologist could introduce directly the outcome variable (\\(W/m^2\\)) without taking into account anything else, if she/he is confident to provide an accurate value. However, in most cases, this information will not be known to the field researcher, and in this situation, these variables can be modeled to different extents of complexity. While, for example, in the case of the most simple simulation, the field archaeologist could ignore deposition rates. In this case, and because we are only considering 14C dates, then the quantity of the sample becomes broadly proportional to the number of people present in a site, and thus it could be modeled like this. However, deposition rates are difficult to ignore if we want to account for the formation process of the archaeological record. If these are known to the archaeologists that developed fieldwork, then this would be the behaviour of the model for creating \\(W/m^2\\). Finally, if these are not known to the archaeologist, but they want to model them, then we would go back to the first DAG. In this case, keep reading for the specificities of the model. This is how each variable works specifically: Waste produced (\\(W/m^2\\) or just \\(W\\)) (outcome variable): Archaeological record present per \\(m^2\\). Since we are considering C14 dates coming from bone, this is the quantity of C14 samples present a time t and at a depth d. Thus, this variable depends on time and depth. \\[W(t,d)=function(t,d)\\]. We have considered this a discrete variable (number of potential samples) with range \\([0,\\propto K]\\). Defined in code as W. The variables time (\\(T\\)) and depth (\\(D\\)) must also be defined. Thus T describes the time, discretely, in years, of existence of the site. For the simulation, this time will be known. Thus, in the simulation \\(T_{birth}=(T=0)\\) and \\(T_{max}=T_{death}\\). Values of \\(T\\) are represented by \\(t\\). D is the depth, in cms, where each specific sample is deposited at a time \\(t\\). This is a continuous variable with range \\([0,\\infty]\\), and for any \\(t\\), we know that \\(0\\leq D(t)\\leq d_0\\) and that \\[D(t)=max\\{D(t-1)-r,0\\} \\tag{1},\\\\ t=1,2,...,T_{max},\\] where \\(r\\) is the natural deposition rates. Population (group size) (\\(P\\)): Discrete variable with range \\([0,\\sim K]\\). Population group size is key to determine anthropogenic deposition rates (which in turn determine \\(W\\)) but it can also be used as a proxy to determine \\(W\\) in case deposition rates are not accounted for since, in any case, \\(W \\propto Pop\\). The model includes the possibility to create a stochastic demographic process (see below), but the user can also set fix values for population or set the parameters in a way that the stochastic process is constrained. In any case, the user does have to provide a value for the carrying capacity (\\(K\\)) as this will limit population growth. Defined in code as Pop. Anthropogenic deposition (\\(A\\)): Amount of bone kilogram/year deposited by each group at a time \\(t\\). This is a continuous variable, with range \\([0,\\infty]\\), measured in Kg. See Anthropogenic deposition protocol for full definition. Natural deposition rates (\\(r\\)): This is a continuous variable, with range \\([0,0.5]\\), measured in cm/year. Because, under normal circumstances, bones are thicker than any possible amount of earth deposited per year, even in a perfectly uncorrupted archaeological sequence (which is what is being modelled here), those would occupy microstrats belonging to different years. This variable is one of the responsibles for how many microstrats will each bone be occupying. See Depth protocol to understand how it works. Defined in code as r. Site function: Has not been considered as a variable per se but, rather, as a group of variables, which are defined by the functionality of the site, and that condition the outcome of \\(A\\). See Anthropogenic deposition protocol to understand how these are modelled. Site type: Site type (whether a site is a cave, a rockshelter or an open-air camp) can heavily condition the deposition rates at any archaeological location. However, in order to reduce uncertainty and not make an overcomplex model, we have decided to embed this condition, and the possible expert knowledge related to it, within the definition of the variable \\(r\\). 4.2 Implementation This simulation for the creation of the archaeological record has been divided in three phases, or protocols. First, we populate the site, according to a stochastic demographic process, second we generate a sample for each time \\(t\\) and, in the third and final step, we distribute the amount of waste for each \\(d\\). In order to fully understand the process, first we will show the protocols and functions used. To start with, let’s inspect the package with the functions functions: ## See some of the archaeoriddle functions Package Topic Title archaeoriddle A_rates Simulate anthropogenic deposition archaeoriddle D_along Depth protocol deposition archaeoriddle Gpd Generation of population dynamics archaeoriddle K_lim Simulation of carrying capacity limitation archaeoriddle Pop_stoch Stochastic population generation archaeoriddle death Simulation of death process 4.2.1 Population \\(Pop\\)-protocol This protocol generates a stochastic demographic process with maximum population \\(\\sim K\\). It is based on three functions. The first function, Gpd(), is the core of the protocol. It receives a population matrix or data.frame with a specific number of individuals (nrow), their age (df[,1]) and their sex (df[,2]) and produces another object with the same format but with a different population based on the current one. Introduced in a loop, this function produces a time series of population, which ensures the Markov property of the stochastic process \\(p(x_n+1|x_n)\\). GpdR Documentation Generation of population dynamics Description Protocol to generate a stochastic demographic process Usage Gpd( x, K, W_fert_age = c(10, 45), M_fert_age = c(15, 55), p_offspring = 0.3, prob = 0.8, ... ) Arguments x Input data with initial population matrix. A data frame or matrix with two columns and nrow equal to the initial population. One row per individual. The first column is the age of the individual. The second column is the sex of the individual, and must be c(\"F\",\"M\"). The columns must be named Age and Sex respectively. K Carrying capacity. W_fert_age Vector with two values. The first value is the youngest age at which is considered that women can have children for prehistoric societies. The second value is the oldest age at which is considered that women can have children. Default is c(10,30). M_fert_age Vector with two values. The first value is the youngest age at which is considered that men can have children for prehistoric societies. The second value is the oldest age at which is considered that men can have children. Default is c(15,40) p_offspring Probability of a woman having a son per year. Default is 0.3. prob Probability that an individual will die per year if total population exceeds K. Default is 0.8 ... Arguments passed to death(). The mortality probability by age matrix. Their arguments can be added. Value data.frame with two columns, where the number of rows is the number of people. The first column contains the ages and the second column contains the sex. However, this function also relies on two the other functions: death() and K_lim(). death() is the process of people dying each year. It is based on an age-structured probability matrix, where infants and old people have more probabilities of deceasing. The matrix is provided, but the user can set its own. K_lim() limits the population when it reaches \\(K\\). The user should specify the appropriate value for \\(K\\) according to the size of the site, its type, the group economy, etc. Also, the user can change the probability that exceeding people dies with parameter prob. Default is 0.8. deathR Documentation Simulation of death process Description For a single individual, returns whether it lives (0) or dies (1) Meant to be used with apply on the population data.frame x Usage death( x, pd = data.frame(Age = c(0:99), P_d = c(rep(0.14, 1), rep(0.16, 4), rep(0.05, 5), rep(0.01, 24), rep(0.03, 14), rep(0.1, 10), rep(0.3, 42))) ) Arguments x A vector or data.frame with a single row from the population matrix. It must contain two values or columns, Age and Sex pd The probability matrix for mortality by age The age-structured data frame is based on Gurven, Kaplan and Supa, 2007. It is extracted adapted after computation from their text (not graphs or tables) Value A value 0 or 1 where 0 = person lives and 1 = person dies, based on pd (the probability matrix) K_limR Documentation Simulation of carrying capacity limitation Description If the population exceeds the carrying capacity, it eliminates oversize with prob probability per person exceeding. Usage K_lim(x, K, prob = 0.8) Arguments x Data frame or matrix. Population (number of people) K Integer. Carrying capacity. Provided by the user prob It is the probability of dying when surpassing carrying capacity Value Returns a data.frame with the updated population In order to account for the chronological occupation of the site, a demographic process must be produced, where the sample is generated accordingly. The function Pop_stoch consider this. Pop_stochR Documentation Stochastic population generation Description It reproduces the population stochastic process. The result is a vector with the number of individuals for each year. Usage Pop_stoch(pop_size, K, ts, prob = 0.8, ...) Arguments pop_size Integer, the initial population K Only if model_pop = TRUE. In this case, it is the carrying capacity ts Time-span, the number of years considered for the process prob Probability that an individual will die if total population exceeds K. Default is 0.8 ... Additional arguments passed to Gpd(), and in turn to death() Value A vector with the population size for each year from 1 to ts If you want to delve into the code of the functions you can open it here: Show code Code ## Function 1. Generation of population dynamics Gpd &lt;- function(x, K, W_fert_age = c(10, 45), M_fert_age = c(15, 55), p_offspring = 0.3, prob = 0.8, ...){ ## Process of having offspring # Female fertile population W &lt;- x[x[,2]==&quot;F&quot;, ] W_fert &lt;- W[W$Age &gt; W_fert_age[1] &amp; W$Age &lt; W_fert_age[2], ] # Male fertile population M &lt;- x[x[,2]==&quot;M&quot;, ] M_fert &lt;- M[M$Age &gt; M_fert_age[1] &amp; M$Age &lt; M_fert_age[2], ] ## Probability of having descendance per woman # Penalisation in case there are too few men pen &lt;- round(nrow(M_fert)*2 / nrow(W_fert), 2) # Assumes one man can have two women pen[pen&gt;1] &lt;- 1 ## The men penalisation can never multiply the birth rate per woman # Probability of a woman having a son per year p_offspring &lt;- p_offspring*pen ## Aging process. They get one year older x$Age &lt;- x$Age+1 ## Births are new population that&#39;s added n_offspring &lt;- sum(rbinom(nrow(W_fert), 1, p_offspring)) new_pop &lt;- data.frame( &quot;Age&quot; = rep(0, n_offspring), &quot;Sex&quot; = sample(c(&quot;M&quot;,&quot;F&quot;), n_offspring, prob=c(0.5, 0.5), replace=TRUE)) x &lt;- rbind(x, new_pop) ## Process of dying vec_d &lt;- apply(x, 1, death, ...) x &lt;- x[vec_d==0, ] ## Apply carrying capacty restrictions x &lt;- K_lim(x, K = K, prob = prob) return(x) } ## Function 2. Simulation of death process death &lt;- function(x, pd=data.frame(&quot;Age&quot; = c(0:99), &quot;P_d&quot; = c(rep(0.14,1), rep(0.16,4), rep(0.05,5), rep(0.01,24), rep(0.03,14), rep(0.1,10), rep(0.3,42)))){ age &lt;- as.numeric(x[1]) return(rbinom(1, 1, prob=pd[pd$Age==age, 2])) } ## Function 3. Simulation of carrying capacity limitation K_lim &lt;- function(x, K, prob=0.8){ p &lt;- nrow(x) if (p&gt;K){ o &lt;- rbinom(p-K, 1, prob) o &lt;- sum(o[o==1]) o[o==0] &lt;- 1 # Avoids problem eliminating all the df if remove == 0 x &lt;- x[-sample(1:nrow(x), o, replace=FALSE), ] } return(x) } ## Function 4. Stochastic population generation Pop_stoch &lt;- function(pop_size, K, ts, prob = 0.8, ...){ ## Create initial population pop_matrix &lt;- data.frame( &quot;Age&quot; = sample(10:30, pop_size, 10:30, replace = TRUE), &quot;Sex&quot; = sample(c(&quot;M&quot;,&quot;F&quot;), pop_size, prob = c(0.5,0.5), replace = TRUE) ) ## Initialize vector with population size for each year pop &lt;- vector(length=ts) pop[0] &lt;- nrow(pop_matrix) ## Run stochastic process for (i in 1:ts){ pop_matrix &lt;- Gpd(pop_matrix, K=K, prob=prob, ...) pop[i] &lt;- nrow(pop_matrix) } return(pop) } 4.2.2 Anthropogenic deposition \\(A\\)-protocol This generates the amount of human waste produced for each \\(t\\) (In kilograms of bone). It is defined as: \\[A(t)= Pop(t)\\times O(t)\\times F(t) \\times G(t),\\\\ \\text{with}\\ t = 1,2,...,T_{death} \\tag{2}\\] Where: \\(Pop(t)\\) is a discrete variable representing the number of living people at a time \\(t\\). \\(O(t)\\) is the proportion of time of the year that the group spends in the camp for each time \\(t\\). It is a continuous variable with range \\([0,1]\\). In the code, this is defined as the parameter in_camp_stay and it is provided as the number of weeks, considering 52 the maximum number of weeks for a year. \\(F(t)\\) is the proportion of bone for the full weight of each Kg of an animal consumed for a time \\(t\\). This is a unit interval variable \\([0,1]\\). \\(G(t)\\) is the quantity, in Kg, of a (full-weight) animal consumed in a site by each individual at a time \\(t\\). This is a continuous variable with range \\([0,\\propto K]\\). This is a hierarchical variable, defined as follows: \\[G(t)=S(t)\\times\\frac{C(t)}{R(t)} = S(t)\\times\\frac{B(t)\\times M(t)}{R(t)} \\tag{3}\\] Where: \\(S(t)\\) is the proportion of meat consumed within the camp. \\([0,1]\\) \\(R(t)\\) is the quantity of kilocalories produced for each kilogram of meat. This is a continuous with range \\([1,2.5]\\). Total kilocalories have been divided by 1000 for easier computation. And \\(C(t)\\) is the quantity of kilocalories, extracted from meat, consumed by person for each time \\(t\\). It is in turned is defined as \\(C(t)=B(t) \\times M(t)\\), where \\(B(t)\\) is the quantity of kilocalories consumed by an individual for each \\(t\\), and it has a range \\([1.5,2.5]\\times 365\\). For easier computation, the actual average of kilocalories consumed per person/day has been divided by 1000. \\(M(t)\\) is the proportion of kilocalories coming from meat relating to the total calories consumed per each individual. \\([0,1]\\). As it can be seen, the above definitions embed the functionality of the site, which can be considered by the user. In practice, setting the variables \\(O(t) = 1\\) and \\(S(t) = 1\\) would eliminate site functionality. This would assume that a site is inhabited by all the group during the full year, and that this group consumes all the food in the site. Up to now, we have obtained the value for the variable \\(A\\), which is the amount of kilograms of bone produced at each time \\(t\\). If we consider 4 grams of non-heated bones per sample, we can extract the number of samples at time \\(t\\), which we cal \\(W(t)\\) \\[W(t)=\\mbox{Integer part of } \\Bigg(\\frac{1000 \\times A(t)}{4} \\Bigg) \\tag{4}\\] This protocol is captured in the following function: A_ratesR Documentation Simulate anthropogenic deposition Description Simulation of samples generated per year (anthropogenic deposition rates) Returns the Kilograms of bone produced per year in a site. Usage A_rates( x, kcalpers = 2, kcalmeat_eat = 0.45, kcalmeat_prod = 1.5, in_camp_eat = 0.55, in_camp_stay = 13, kg = 0.07 ) Arguments x Integer (user provided), vector or data.frame. If integer, it is the number of people inhabiting the site. If data.frame, the number of people is the number of rows. If vector, it is the length of the vector. It is Pop(t) in equation 3 kcalpers Quantity of kilocalories consumed per day per adult person. It corresponds to B(t) in the equation 3. But in the formula it is per year. Tt has a range of &#8288;[1.5,2.5]&#8288;. Default is 2. kcalmeat_eat Proportion of kilocalories extracted from meat. Range 0,1. Default is 0.45, based on Cordain et al (2000). It is M(t) in equation 3. kcalmeat_prod Quantity of kiocalories per meat kilogram. Range 1,2.5 Default is 1.5, considering goat meat. It is R(t) in euqation 3. in_camp_eat Proportion of food consumed within the camp. Range 0,1. Default is 0.55 based on Collette-Barbesque et al. (2016). S(t) in equation 3. in_camp_stay Proportion of time spent in a specific camp. Valid for groups with high mobility. The proportion is computed within the function, but the user introduces the weeks of occupation of the camp, where the maximum is 52 (full year). Default is 13 (weeks, or 0.25 of the year, or three months a year). It corresponds to O(t) in equation 3. kg Bone proportion for each animal consumed. Default is 0.07 based on Johnston et al. (2021). It corresponds to F(t) in equation 3. Value The number of samples You can inspect the A_rates code here: Show code Code ## Function 5. Simulate anthropogenic deposition A_rates &lt;- function(x, kcalpers = 2, kcalmeat_eat = 0.45, kcalmeat_prod = 1.5, in_camp_eat = 0.55, in_camp_stay = 13, kg = 0.07){ if (is.data.frame(x) == TRUE){ P &lt;- nrow(x) } else if (length(x) == 1){ P &lt;- x } else { P &lt;- length(x) } # Check variable values are within the defined ranges if (1.5 &lt;= kcalpers &amp; kcalpers &lt;= 2.5){ B &lt;- kcalpers*365 } else { stop(&#39;kcalpers must be within [1.5, 2.5]&#39;) } if (0 &lt;= kcalmeat_eat &amp; kcalmeat_eat &lt;= 1) { M &lt;- kcalmeat_eat } else { stop(&#39;kcalmeat_eat must be within [0, 1]&#39;) } if (1 &lt;= kcalmeat_prod &amp; kcalmeat_prod &lt; 2.5) { R &lt;- kcalmeat_prod } else { stop(&#39;kcalmeat_prod must be within [1, 25]&#39;) } if (0 &lt;= in_camp_eat &amp; in_camp_eat &lt;= 1){ S &lt;- in_camp_eat } else { stop(&#39;in_camp_eat must be within [0, 1]&#39;) } if (in_camp_stay &lt;= 52){ O &lt;- round(in_camp_stay/52,2) } else { stop(&#39;A year cannot have more than 52 weeks&#39;) } C &lt;- B*M G &lt;- (C * S) / R ## Quantity (in kg) of animal consumed per person in camp during year t A &lt;- P * O * kg * G ## kilograms of meat consumed within a camp by the group W &lt;- round((1000 * A) / 4) ## samples extracted from that meat return(W) } 4.2.3 Depth \\(D\\)-protocol This protocol is designed to respond to the fact that, despite a bone is deposited at time \\(t\\), it can occupy the estratigraphic space of many subsequent years until it is fully buried. The amount of years it takes to be fully buried depends on the thickness of the bone and the natural deposition rates \\(r\\). Since the thickest bones are usually the minority within a sample, while the majority is usually conformed of smaller bones, we have considered that bone presence decreases exponentially from \\(t_0\\), the year when it was deposited. Thus, this process is modeled as follows: \\[W_b(t_u,t_l)=W(t=t_l)\\times(1-e^{-\\lambda(t_u-t_l)}),\\ t_u &lt; t_l \\tag{5}\\] Where \\(W\\) as defined before, it is the number of samples deposited at a time \\(t_l\\) \\(W_b\\): is the number of samples buried at a time \\(t_u\\) from the ones generated at \\(t_l\\). Thus, \\(t_u \\geq t_l\\) \\(t_l\\) is the moment in time \\(t\\) when the samples \\(W\\) are deposited. \\(t_u\\) is each time \\(t\\), \\(t \\geq t_l\\), when the sample is being buried according to the parameter \\(r\\). At \\(t_{u_{max}}\\), the sample is completely buried. \\(t_{u_{max}}&gt;=t_u&gt;=t_l\\) \\(t_{u_{max}}\\) depends on two factors: \\(L\\) is maximum thickness of the thickest bone in the direction of the deposition, in cm. \\(r\\) is the natural deposition rate, in \\(\\mbox{cm/year}\\). For this model, we have considered the values 0.1, 0.2, 0.3, 0.4 and 0.5 Thus we can calculate the time it takes for a sample to be fully buried as \\[r = \\frac{L}{t_{u_{max}}} \\Rightarrow t_{u_{max}}=\\frac{L}{r} \\tag{6}\\] Estimation of \\(\\lambda\\) Now we need to estimate the exponential rate \\(\\lambda\\) in equation \\((5)\\). In order to do so, we consider the state of the model when \\(t_l=0\\) and \\(t_u=t_{u_{max}}\\), which marks the time at which the first samples deposited are completely buried. And consider the following \\[\\frac{W_b(t_u,t_l)}{W(t=t_l)} \\tag{7}\\] is the proportion of buried samples in \\(t_{u}\\) from the ones that were deposited in \\(t_l\\). Thus, if we substitute the time points specified above and plug in equation 5, we have that \\[\\frac{W_b(t_u=t_{u_{max}},t_l)}{W(t_l=1)}=1-e^{-t_{u_{max}}\\lambda} \\tag{8}\\] However, since we consider that all of the samples buried in \\(t_{u_{max}}\\), then the proportion on the left hand side is 1, and in this situation \\(\\lambda \\rightarrow \\infty\\) so we cannot use the equation. We can especify an error margin, \\(\\theta_e\\) to the proportion of buried samples in \\(t_{u_{max}}\\), say \\(99\\%\\). In this case, \\(\\lambda\\) can be easily computed as follows \\[\\theta_e=1-e^{-\\lambda t_{u_{max}}}\\] and thus, solving for \\(\\lambda\\) and taking logarithms on both sides, \\[\\lambda=\\frac{-log(1-\\theta_e)}{t_{u_{max}}} \\tag{9}\\] Where \\(\\theta_b&lt;1\\) is the proportion of buried samples in \\(t_{u_{max}}\\), which is calculated in equation 6. The function D_along captures this process: D_alongR Documentation Depth protocol deposition Description It distributes the samples produced in one specific year along the depth of the site, without any kind of post-depositional alteration, and according to pre-established post-deposition rates. Returns a vector with the samples exponentially distributed. The vector is as long as L/r and the error (prop_buried, \\theta_{\\epsilon}) is considered. Usage D_along( W_t, r, max_bone_thickness = c(\"m\", \"s\", \"l\", \"vl\"), prop_buried = 0.9999 ) Arguments W_t Integer (user provided), vector or data.frame. It is the number samples produced at a specific 't'. r Is the natural deposition rates. At this moment. Values greater than 0.5 are not accepted. If values with two or more decimals are provided, the function will automatically round the value to one decimal. max_bone_thickness Maximum thickness of bones within the assemblage. Four values are possible: 's' (small) = 2.5 cm; 'm' (medium) = 5 cm; 'l' (large) = 10 cm and 'vl' (very large) = 20 cm. Default is 'm'. prop_buried Proportion of samples buried sample at tmax, considering error. Pb needs to be smaller than 1. Default is 0.9999, which stands for 99.99%. This is \\theta_{\\epsilon} in equation 9 Value A vector of samples buried at times from tl to tm At the end, the function Rec_c runs D_along over a period of time, effectively producing an archaeological record. In the function Rec_c the user can consider whether to divide the total sample by the area of the site, or not. In addition, the user can use the modeled values (with the functions above) as an input to this function, or introduce them directly, for example, in the case that fix population rates per year were preferred. Rec_cR Documentation Archaeological deposition record Description Generate archaeological deposition record over time and depth It iterates over D_along to spread the amount of samples produced at each time point over different profundities Usage Rec_c(x, area, ts, InitBP, persqm = FALSE, ...) Arguments x Vector with the number of samples per year. As produced as produced by iterating over A_rates. area Only if persqm = TRUE. In this case, the total area of the site must be provided ts Time-span, the number of years considered for the process InitBP Initial year considered for the process. In BP. persqm If TRUE, the total record is divided by the area of the site (in square meters), so that the output is per square meter. Default is FALSE ... This function uses the functions D_along(). The additional arguments can be added. Value A square matrix of size ts. It contains the amount of samples deposited at each year (columns) and each depth (rows) As before, you can check the code here: Show code Code ## Function 6. Depth protocol deposition D_along &lt;- function(W_t, r, max_bone_thickness = c(&quot;m&quot;, &#39;s&#39;, &#39;l&#39;, &#39;vl&#39;), prop_buried = .9999){ # Define parameter r if(r &gt; 0.5) stop(&quot;values &gt; 0.5 are not accepted for param &#39;r&#39;&quot;) r &lt;- round(r, 1) # Constraints for parameter Pb if (prop_buried &gt;= 1) stop(&quot;Pb must be lower than 1&quot;) # Define parameter Max_bone_thickness (L) max_bone_thickness = match.arg(max_bone_thickness) if (max_bone_thickness == &#39;s&#39;){ L &lt;- 2.5 } else if (max_bone_thickness == &#39;m&#39;){ L &lt;- 5 } else if (max_bone_thickness == &#39;l&#39;){ L &lt;- 10 } else if (max_bone_thickness == &#39;vl&#39;){ L &lt;- 20 } # Define tmax tm &lt;- L/r # Estimate lambda l &lt;- -log(1 - prop_buried) / tm ss &lt;- rep(0, round(tm)) ## Vector to distribute samples over tl &lt;- 0 # Year where the sample is deposited tu &lt;- 1 # Year when it is covered for (i in 1:tm){ Wb &lt;- W_t * (1 - exp(-l*(tu-tl))) # Apply formula for tu Wbprev &lt;- W_t * (1 - exp(-l*((tu-1)-tl))) # Calculate for previous to tu ss[i] &lt;- round(Wb - Wbprev) # Number of samples for each year tu &lt;- tu + 1 } return(ss) } ## 7. Archaeological deposition record Rec_c &lt;- function(x, area, ts, InitBP, persqm = FALSE, ...){ ## Whether sqm division must be included or not if (persqm == TRUE){ x &lt;- x / area } ## Spread dates along different depths matdim &lt;- length(x) mat &lt;- matrix(nrow=matdim, ncol=matdim) for (i in 1:matdim){ new &lt;- D_along(x[i], ...) st &lt;- i - 1 pos &lt;- c(rep(0, st), new) pos &lt;- pos[1:matdim] mat[, i] &lt;- pos } mat[is.na(mat)] &lt;- 0 ## Names for columns (each year) years &lt;- seq(InitBP, InitBP-ts) nyears &lt;- c() for (i in 1:matdim){ nyears[i] &lt;- paste0(years[i], &quot; BP&quot;) } colnames(mat) &lt;- nyears ## Names for rows (each depth) # Extract arguments as a list extract_args &lt;- function(x, ...){ extras &lt;- list(...) return(list(extras=extras)) } dr &lt;- extract_args(D_along, ...) dr &lt;- dr$extras$r d &lt;- rev(cumsum(rep(dr, nrow(mat)))) ## computes depths rownames(mat) &lt;- paste0(&quot;d = &quot;, d, &quot; cm&quot;) return(mat) } 4.3 Example and simulation With the above functions, the user can model (1) a generative demographic process, (2) how many samples would a group of people produce in a site, according to different constraints and (3) how those dates distribute along the depth of a site under the assumption that there has not been any kind of record loss or post-depositional process (this will be modelled in a second layer of modelling). We can start the simulation with the parameters seen below (or defaults in function definitions above). To sum up, these are the steps of the simulation: \\(Pop\\)-protocol. Using Pop_stoch, we generate a stochastic population dynamic that will give us the number of individuals for each year. \\(A\\)-protocol. Knowing the population size per year, we apply A_rates to each of them and generate the anthropogenic deposition, and get the number of samples per year. \\(D\\)-protocol. Knowing how many samples are generates each year, using Rec_c, we distribute them along the depth record. set.seed(1234) # 1. Pop-protocol Ps &lt;- Pop_stoch(pop_size=100, ts=100, K=150) # 2. A-protocol samp &lt;- unlist(lapply(Ps, A_rates)) ## Extract sample per time steps # 3. D-protocol Rec &lt;- Rec_c(samp, InitBP = 7500, ts = 100, r = 0.2, max_bone_thickness = &quot;m&quot;) With this we obtain, among other things, the distribution of the samples deposited for each date along the depth of the sit, and its comparison to the total population. For better comprehension, we have decided not to include all of the dates in the plot below, but only some of them as an example. The user can also check how the model works and its results here. The total number of population has been adapted for visualisation Notice the exponential decay in the amount of samples per depth layer for the same year. "],["record-loss.html", "5 Record loss 5.1 Theoretical model 5.2 Implementation Short-term taphonomic loss Long-term taphonomic loss", " 5 Record loss 5.1 Theoretical model 5.1.1 General purpose Our main interest is showing and testing the effect of post-depositional processes on the archaeological record. The most obvious consequence of these effects relates to the direct loss of the record, while other implications can result in vertical and horizontal movements. Such movements, in turn, distort our comprehension of an archaeological site. Although the horizontal disposition of archaeological waste is important to understand different aspects, such as the activities deployed in a site, the function of that site, or it can even bring information on demographic processes, it will not be taken into account here. The reason for this is that modelling horizontal post-depositional movements (1) requires specific types of information which are frequently not available for field researchers, (2) adds complexity layers, the payoff of which, given its cost in terms of computation and comprehension of the model, may be insufficient and (3) as the focus of this model is on the reliability of 14C dates, vertical movements, which can obscure the construction of consistent stratigraphies, have been given preference. However, we understand that horizontal movement is a key aspect of the record formation. For example, it is frequent that hydric, gullying or sloping processes concentrate the archaeological waste in specific parts of the site. This would bias our perception of record concentration both horizontally, but also vertically. This record loss model assumes and normalises this when \\(W(t)\\) is retrieved from the previous record formation model. Nevertheless, this needs to be taken into account both if the user wants to introduce the values for \\(W(t)\\), and for the analysis with real archaeological data. There is not a single solution to control for this, as it largely depends on the excavated area and whether this is representative for the complete site or not. For example, many surveys spread across a site could actually be representative of that site’s record, whereas a single small survey in that same site is likely prone to present some specific bias due to post-depostional conditions. In this case, and in order to propose a correct variable, the user needs to make the proper calculations according to the site under study, but always bearing in mind that the model will work over the variable \\(W(t)\\) (waste produced), and can be computed to be expressed by \\(m^2\\). 5.1.2 Model layers Although in the future we will introduce additional layers which account for how the record moves vertically along the sequence, at this point, we are only considering the processes of record loss. 5.1.2.1 Loss of the record The are two main components for this part of the model. As shown in the graph below, the first one is time-dependent taphonomic loss, usually referring to long term process affecting the record for every \\(t\\) from the moment of its depositions to the present. The second one is direct action, which consider high-impact short term processes, such as human or animal action. These two variables can be applied together (advised), separately or not at all. These variables are modelled as follows: Long-term loss (\\(V_l(t)\\): Attending to the proxy we are considering (bones), we understand this variable as the processes which on the short term have little to none impact on bone preservation, but which can have severe consequences in the long term. These can refer, for example to the pH of the soil of the site, temperature and humidity changes, etc, and must be considered by the researcher or the user. We can subsume this information as a single probability \\(\\theta_l\\) within a binomial distribution. Then, the number of archaeological samples currently surviving from all the \\(W(t)\\) generated at a time \\(t\\) follows the distribution \\[V_l(t) \\sim Bi(W(t), \\theta_l) \\tag{1}\\] Although mathematically this computation is straightforward, it can be quite expensive computationally. Therefore, because we can assume independence of the effect altering the sample for each \\(t\\), and for computational efficiency, we compute \\(\\theta_l\\) as \\[\\theta_l = \\theta^{t+1950} \\tag{2}\\] Where \\(\\theta_l\\) is the considered probability, \\(t\\) is the time period before present where the sample was deposited and 1950 is the year that is conventionally treated as the present in radiocarbon dating. Short-term loss (\\(V_s(t+1)\\)): Most of the short-term, high-impact destruction of the archaeological record happens during the first year after deposition. Therefore, for this variable, we have considered the effect acting only once on the archaeological record, with an action, in any case, more agressive than the previous variable. Again, we can consider this a binomial distribution, where \\[V_s(t+1)\\sim Bi(W(t),\\theta_s)\\] where \\(\\theta_s\\) is the probability that the record survives. Again, this probability must be estimated according to previous information such as, for exemple, whether there has been human reoccupation or animal action at the site at \\(t +1\\). In this case, one good way to measure this is considering that for \\(\\theta_s = 0.5\\), half the record would be lost after this first year. All in all, if we put together these variables, then the remaining record for a site could be defined as \\[V(t)=V_l(t)+V_s(t+1)\\] There have been other quantitative approaches to the survival of the archaeological record, such as Surovell’s (2007, 2009) approaches. These are rather focused on the loss of complete sites, and not that much on the loss of specific records. And, as the authors acknowledge, they refer to specific geographic locations. However, with specific parameter combinations of our loss probabilities, we can obtain correlations higher than 0.98 with Surovell’s loss curves. In the case shown, for example, we have considered \\(\\theta_s=0.9\\) and \\(\\theta_l=0.9997\\) ## Warning in cor(x, y): the standard deviation is zero ## Warning in cor(x, y): the standard deviation is zero 5.2 Implementation This layer of the model is less complex than the previous one. In this case, we only need to apply the loss of the record on the already created sample, according to the different loss probabilities. The functions for this are used as follows. short_lossR Documentation Short-term taphonomic loss Description Simulates the short-term taphonomic loss applying binomials to values on a single vector for 1 year. If used for many years, use with apply function, where the rows of the data frame are the depths and the columns the years. Usage short_loss(x, theta_s) Arguments x: A vector with the amount of samples per depth, at a specific years. theta_s: Probability of the record surviving after the first year after deposition Value numeric with reduced values due to the short-term taphonomic loss long_lossR Documentation Long-term taphonomic loss Description Simulates the long-term taphonomic loss applying binomials to values on a single vector for 1 year. If used for many years, use with apply function, where the rows of the data frame are the depths and the columns the years. Usage long_loss(x, theta_l, it) Arguments x: A vector with the amount of sample per depth. theta_l: Probability of the record surviving after the first year after deposition it: Initial time. Initial year of occupation in BP. Value numeric with reduced values due to long-term taphonomic loss You can check the code for the short and long-term loss functions here: Show code Code ## Function 8. Short term taphonomic loss short_loss &lt;- function(x, theta_s){ res &lt;- c() for (i in 1:length(x)){ res[i] &lt;- rbinom(1, x[i], theta_s) } return(res) } ## Function 9. Long term taphonomic loss long_loss &lt;- function(x, theta_l, it){ t &lt;- it+1950 for (i in 1:ncol(x)){ prob &lt;- theta_l^(t-i) s &lt;- x[, i] for (k in 1:length(s)){ s[k] &lt;- rbinom(1, s[k], prob) } x[, i] &lt;- s } return(x) } Once this is done, it is fairly easy to recompute the remaining record, and show it in the same terms as before. In this case, we have computed the record loss with \\(\\theta_s=0.9\\) and \\(\\theta_l=0.9997\\). Again, the user can heck how the model work and its results here. tlRec &lt;- apply(Rec, 2, short_loss, th_s) lRec &lt;- long_loss(tlRec, th_l, 7500) tlRec &lt;- t(lRec) library(viridis) barplot(tlRec[c(1:4,77:79),], col = viridis(10), legend = colnames(Rec)[c(1:4,77:79)], xlab = &quot;Depth&quot;, ylab = &quot;nsamples&quot;, main = &quot;Distribution of specific years along depth with population&quot;) lines(Ps*300, col = &quot;darkred&quot;, lwd = 1.5) colnames(tlRec) &lt;- colnames(tRec) rownames(tlRec) &lt;- rownames(tRec) barplot(tRec, col = viridis(ncol(tRec)), #legend = colnames(Rec), xlab = &quot;Depth&quot;, ylab = &quot;nsamples&quot;, main = &quot;Distribution of samples for specific years&quot;) barplot(tlRec, col = viridis(ncol(tlRec)), #legend = colnames(Rec), xlab = &quot;Depth&quot;, ylab = &quot;nsamples&quot;, main = &quot;Distribution of samples for specific years after loss&quot;) "],["final-choice-and-simulation.html", "6 Final Choice and simulation", " 6 Final Choice and simulation As I (simon) am stupid I didn’t generate seeds for each experiment so we cannot re-run it EXACTLY the same. But I kept lot of informations and output about it. They are stored in the folder general_results_selected_simu/ and will allow us to reconstruct most of what happened. We basically run thousands of simulations and choose the one who looked the cool 😆. We used the script scriptmini.R that allow to run one simulation and ran in in parallel as described in smallscript.md. What scriptmini.R doesn basically is We first load the maps and the sites: sites=vect(&quot;data_original/sitesinitialposition/&quot;) run one simulation ts=1000 expname=&quot;basar&quot; print(paste0(&quot;Starting simulation &quot;,expname)) onesimu=run_simulation ( sites=sites, viable=viable, dem=height.ras, ressources=rast(&quot;data_original/resources.tiff&quot;), water=height.wat, foldervid=expname, visu=F,visumin=TRUE, ts=ts,#length of simulation in year Kbase=c(&quot;HG&quot;=35,&quot;F&quot;=110),#difference in K for the two cultures cul_ext=c(&quot;HG&quot;=7,&quot;F&quot;=6),#spatial penality to extent: lower, bigger penality penal_cul=c(&quot;HG&quot;=4,&quot;F&quot;=5),#penality of occupational area: low, other sites can cam close prob_birth=c(&quot;HG&quot;=0.3,&quot;F&quot;=0.5),#proba to give birth every year prob_survive=c(&quot;HG&quot;=0.8,&quot;F&quot;=0.65),#proba to die when pop &gt; K prob_split=c(&quot;HG&quot;=.5,&quot;F&quot;=.6),#proba to create new settlement when Ne &gt; K minimals=c(&quot;HG&quot;=.14,&quot;F&quot;=.20),#how big the group of migrant should be to create a new city vs migrate to a existing one bufferatack=300,#distance max around which settlement can fight prob_move=c(&quot;HG&quot;=0.2,&quot;F&quot;=0.1) #proba to migrate to existing settlement when Ne &gt; K ) generate a few output, including a video that helps to select the good simulation, these things are also do by scriptmini.R: Nts=onesimu$Nts warcasualties=onesimu$warcasualties sites=onesimu$sites i=min(ts,which(apply(Nts,1,sum)==0)) pdf(paste0(expname,&quot;_mapFinal.pdf&quot;)) plotMap(height.ras,height.wat,paste0(&quot;year &quot;,i)) plot(sites,cex=(as.integer(Nts[i,]&gt;0)*0.3+Nts[i,]/200),pch=21,add=T,bg=rainbow(2,alpha=.6)[as.factor(sites$culture)]) text(sites) dev.off() pdf(paste0(expname,&quot;growth_utils.pdf&quot;)) plot(2:i,warcasualties[1:(i-1)],lwd=2,col=&quot;green&quot;,type=&quot;h&quot;,yaxt=&quot;n&quot;,ylab=&quot;&quot;,xlim=c(0,i)) axis(4) par(new=T) growF=apply(Nts[1:i,sites$culture==&quot;F&quot;],1,sum) growHG=apply(Nts[1:i,sites$culture==&quot;HG&quot;],1,sum) plot(growF,col=&quot;red&quot;,type=&quot;l&quot;,lwd=2,ylim=c(0,max(growF,growHG)),xlim=c(0,i)) points(growHG,col=&quot;blue&quot;,lwd=2,type=&quot;l&quot;) dev.off() pdf(paste0(expname,&quot;growth_tot.pdf&quot;)) plot(warcasualties[1:i-1],lwd=2,col=&quot;green&quot;,type=&quot;h&quot;,yaxt=&quot;n&quot;,ylab=&quot;&quot;) axis(4) par(new=T) growT=apply(Nts[1:i,],1,sum) plot(growT,col=&quot;black&quot;,type=&quot;l&quot;,lwd=2,ylim=c(0,max(growT))) dev.off() Let’s redo that with the selected simulation: onesimu=readRDS(&quot;data_original/general_results_selected_simu/buffattack300_K110_PSU065_3_all.RDS&quot;) #Nts=readRDS(&quot;nts&quot;) #warcasualties=readRDS(&quot;war&quot;) #sites=terra::vect(readRDS(&quot;general_results_selected_simu/buffattack300_K110_PSU065_3_sitesRast.RDS&quot;)) Nts=onesimu$Nts warcasualties=onesimu$warcasualties Plot the sites at the beginning # source(&quot;tools.R&quot;) #expname=&quot;general_results_selected_simu/buffattack300_K110_PSU065_3&quot; #sites=vect(readRDS(paste0(expname,&quot;_sitesRast.RDS&quot;))) sites=vect(&quot;data_original/sitesinitialposition/&quot;) height.ras=rast(&quot;data_original/east_narnia4x.tif&quot;) height.wat=height.ras height.wat[height.wat&gt;mean(height.wat[])]=NA i=1 plotMap(height.ras,height.wat,paste0(&quot;year &quot;,i,&quot;, when it all begins&quot;)) plot(sites,cex=(as.integer(Nts[1,]&gt;0)*0.5+Nts[1,]/100),pch=21,add=T,bg=rainbow(2,alpha=.6)[as.factor(sites$culture)]) text(sites[Nts[1,]&gt;0],pos=3) We can look at the war and the number of deaths for each battle i=1000 plot(2:i,warcasualties[1:(i-1)],lwd=2,col=&quot;dark red&quot;,type=&quot;h&quot;,ylab=&quot;# dead&quot;,xlim=c(0,i)) Comparison to the total population growth of each culture i=1000 par(mar=c(5,5,1,5)) plot(2:i,warcasualties[1:(i-1)],lwd=2,col=&quot;dark red&quot;,type=&quot;h&quot;,yaxt=&quot;n&quot;,ylab=&quot;&quot;,xlim=c(0,i),xlab=&quot;time&quot;) axis(4) mtext(&quot;# dead&quot;,4,2.5) par(new=T) growF=apply(Nts[1:i,sites$culture==&quot;F&quot;],1,sum) growHG=apply(Nts[1:i,sites$culture==&quot;HG&quot;],1,sum) plot(growF,col=&quot;orange&quot;,type=&quot;l&quot;,lwd=5,ylim=c(0,max(growF,growHG)),xlim=c(0,i),ylab=&quot;pop&quot;,xlab=&quot;&quot;) points(growHG,col=&quot;blue&quot;,lwd=5,type=&quot;l&quot;) If we look at the total population size, we can see how the clashes slowed down the population growth: par(mar=c(5,5,1,5)) plot(2:i,warcasualties[1:(i-1)],lwd=2,col=&quot;dark red&quot;,type=&quot;h&quot;,yaxt=&quot;n&quot;,ylab=&quot;&quot;,xlim=c(0,i),xlab=&quot;time&quot;) axis(4) mtext(&quot;# dead&quot;,4,2.5) par(new=T) growT=apply(Nts,1,sum) plot(growT,col=&quot;black&quot;,type=&quot;l&quot;,lwd=5,ylim=c(0,max(growT)),xlim=c(0,i),ylab=&quot;pop&quot;,xlab=&quot;&quot;) This show if we looka at the growth rate: plot(diff(growT,lag=100),type=&quot;l&quot;) Replaying all that will give this: "],["generate-archaeological-remaind-and-squares.html", "7 Generate Archaeological remaind and squares 7.1 Using sites size to generate deposite 7.2 Split environment in a grid", " 7 Generate Archaeological remaind and squares 7.1 Using sites size to generate deposite This has been done using file dateGeneration.R, we will describe it here now. First we get the result of a simulation. height.ras=rast(&quot;data_original/east_narnia4x.tif&quot;) height.wat=height.ras height.wat[height.wat&gt;mean(height.wat[])]=NA height.groups=height.ras maxh=max(height.ras[],na.rm=T) height.groups[height.groups&lt;mean(height.groups[])]=NA height.groups[height.groups&lt;(maxh*.7)]=1 height.groups[height.groups&gt;(maxh*.7)]=200 height.groups[is.na(height.groups)]=-1 height.poly=as.polygons(height.groups) viable=makeValid(height.poly[2,]) expname=&quot;data_original/general_results_selected_simu/buffattack300_K110_PSU065_3&quot; onesimu=readRDS(paste0(expname,&quot;_all.RDS&quot;)) sites=readRDS(paste0(expname,&quot;_sitesRast.RDS&quot;)) if(class(sites)[1] == &quot;PackedSpatVector&quot;) sites=terra::vect(sites) Nts=onesimu$Nts #alldeposit=lapply(1:ncol(Nts),function(s)Rec_c(sapply(Nts[1:i,s],A_rates), InitBP = 7500,ts=ts,r = 0.2, Max_bone_thickness = &quot;m&quot;)) #allShortLoss=lapply(1:10,function(ind){Rec=alldeposit[[ind]];print(paste0(&quot;settlement #&quot;,ind));apply(Rec,2,short_loss,.6)}) #allShortLoss=lapply(allShortLoss,function(Rec)long_loss(Rec,.9997,7500)) Using Rec_c , short_loss and long_loss we generate deposit. Generating everything can take long time but it’s basically done like this: #All in one: alldeposit=lapply(1:ncol(Nts),function(s)Rec_c(sapply(Nts[,s],A_rates), InitBP = 7500,ts=ncol(Nts),r = 0.2, Max_bone_thickness = &quot;m&quot;)) allLosses=lapply(1:length(alldeposit),function(ind){ st=Sys.time() print(paste0(&quot;settlement #&quot;,ind)); Rec=alldeposit[[ind]]; Rec=apply(Rec,2,short_loss,.6) #apply short loss Rec=long_loss(Rec,.9997,7500) #apply long loss print(Sys.time()-st) return(Rec) }) rm(alldeposit) Remove where to small maxSites=max(sapply(allLosses,sum)) nsample=round(sapply(allLosses,sum)*30/maxSites) allRemainingDates=lapply(seq_along(allLosses),function(r)extractDates(allLosses[[r]],n=nsample[r])) rm(allLosses) #object are big, need to free memory #pdf(paste0(expname,&quot;_mapFound.pdf&quot;)) #plotMap(height.ras,height.wat,paste0(&quot;final after losses&quot;)) #plot(sites[1:10,],cex=3*(lengths(allRemainingDates)-1)/(29),pch=21,add=T,bg=rainbow(2,alpha=.6)[as.factor(sites$culture[1:10])]) #dev.off() dates=unique(unlist(allRemainingDates)) dates=rev(sort(dates[!is.na(dates)])) plot(table(unlist(allRemainingDates))) totallDatesRemains=sapply(allRemainingDates,function(i)table(factor(i,levels=dates))) saveRDS(allRemainingDates,file=paste0(expname,&quot;_dates.RDS&quot;)) From this we have, for every site, a list of date(s) This has been done using the script exploreDate.R but will be explained here: Loading simulation results, green are the sites who survived, dots are all the site that existed. height.ras=rast(&quot;data_original/east_narnia4x.tif&quot;) height.wat=height.ras height.wat[height.wat&gt;mean(height.wat[])]=NA Nts=readRDS(&quot;data_original/general_results_selected_simu/buffattack300_K110_PSU065_3_all.RDS&quot;)$Nts ress=rast(&quot;data_original/resources.tiff&quot;) allsites=readRDS(&quot;data_original/general_results_selected_simu/buffattack300_K110_PSU065_3_sitesRast.RDS&quot;) if(class(allsites)[1] == &quot;PackedSpatVector&quot;) allsites=terra::vect(allsites) plotMap(height.ras,height.wat) plot(allsites,add=T) plot(allsites[Nts[nrow(Nts),]&gt;0,],add=T,pch=21,bg=&quot;green&quot;,cex=Nts[nrow(Nts),]/60) Loading dates: dates=readRDS(&quot;data_original/general_results_selected_simu/buffattack300_K110_PSU065_3_dates.RDS&quot;) Keep sites with foundable dates foundsites=allsites[lengths(dates)&gt;0,] foundsites$numdates=unlist(lengths(dates[lengths(dates)&gt;0])) founddates=dates[lengths(dates)&gt;0] Remove BP to the dates, add some random variation stdpool=c(20,30,40,50,60,80,100,120) founddates=lapply(founddates,sort) founddates=lapply(founddates,gsub,pattern=&quot; BP&quot;,replacement=&quot;&quot;) founddates=lapply(founddates,rev) founddates=lapply(founddates,function(i)paste0(i,&quot; ± &quot;,sample(stdpool,length(i),replace=T,prob=c(3,3,3,3,2,2,1,1)),&quot; BP&quot;)) foundsites$dates=sapply(founddates,paste0,collapse=&quot; | &quot;) plotMap(height.ras,height.wat) plot(foundsites,cex=foundsites$numdates/20+1,pch=21,bg=as.factor(foundsites$culture),add=T) 7.2 Split environment in a grid Split the environment in grids and extract date for each grid leftdates=dates[lengths(dates)&gt;0] plotMap(height.ras,height.wat) plot(foundsites,cex=foundsites$numdates/20+.1,pch=21,bg=1,add=T) squares=st_make_grid(height.ras,.5) plot(squares,add=T,col=adjustcolor(rainbow(length(squares)),.35)) text(st_coordinates(st_centroid(squares)),label=1:length(squares),col=&quot;white&quot;) text(st_coordinates(st_centroid(squares)),label=1:length(squares),col=&quot;white&quot;) Public selection plotMap(height.ras,height.wat) plot(foundsites,cex=foundsites$numdates/20+1,pch=21,bg=as.factor(foundsites$culture),add=T) selection=c(14,30,45,65,66) plot(squares[selection],add=T,col=adjustcolor(&quot;blue&quot;,.3)) inter=st_intersection(st_as_sf(foundsites),squares[selection]) ## Warning: attribute variables are assumed to be spatially constant throughout ## all geometries plotMap(height.ras,height.wat) plot(st_geometry(inter),add=T,bg=rainbow(2,alpha=.6)[as.factor(inter$culture)],pch=21,cex=1+inter$numdates/10) Giving name to the publicly available data The names have bee ngenerated via: fantasynamegenerators.com site_dist=st_distance(inter) #min(site_dist[as.numeric(site_dist)&gt;units(0)]) sitesnames=1:nrow(inter) sitesnames[c(1:4, 20)]=c(&quot;Farwallow&quot; ,&quot;Bearcall&quot; ,&quot;Dustscar&quot; ,&quot;Clearreach&quot; ,&quot;Rabbithole&quot;) fr=c(&quot;Épibéliard&quot; ,&quot;Cololuçon&quot; ,&quot;Pulogne&quot; ,&quot;Haguemasse&quot; ,&quot;Auriteaux&quot; ,&quot;Bourville&quot; ,&quot;Banau&quot; ,&quot;Montnesse&quot; ,&quot;Bannet&quot; ,&quot;Alenlon&quot;, &quot;Roullac&quot; ,&quot;Genneville&quot; ,&quot;Vinlès&quot; ,&quot;Antonnet&quot; ,&quot;Courtou&quot; ,&quot;Beaulogne&quot; ,&quot;Coloville&quot; ,&quot;Sarsart&quot; ,&quot;Soilon&quot; ,&quot;Cololimar&quot;) sitesnames[5:19]=fr[1:(19-4)] spain=c(&quot;Zava&quot; ,&quot;Catadrid&quot; ,&quot;Tegon&quot; ,&quot;Alicia&quot; ,&quot;Mulid&quot; ,&quot;Zararbella&quot; ,&quot;Malid&quot; ,&quot;Cásca&quot; ,&quot;Granalejos&quot; ,&quot;Segorez&quot; ,&quot;Terteixo&quot; ,&quot;Astumanca&quot; ,&quot;Galle&quot; ,&quot;Talona&quot; ,&quot;Girovega&quot; ,&quot;Albanada&quot; ,&quot;Nadoba&quot; ,&quot;Senca&quot; ,&quot;Vallanca&quot; ,&quot;Taville&quot;) sitesnames[21:length(sitesnames)]=spain[1:(length(sitesnames)-20)] inter=cbind(inter,sitesnames) plotMap(height.ras,height.wat) plot(st_geometry(inter),add=T,bg=rainbow(2,alpha=.6)[as.factor(inter$culture)],pch=21,cex=1+inter$numdates/10) text(st_coordinates(inter),inter$sitesnames,cex=.8) Export csv and data for each public square inter$sitesnames=sitesnames for(g in selection){ curr=inter[inter$ID==g,] coords=st_coordinates(curr) write.csv(file=paste0(&quot;square_&quot;,g,&quot;.csv&quot;),cbind.data.frame(sitename=curr$sitesnames,lon=coords[,1],lat=coords[,2],dates=curr$dates,economy=curr$culture)) } Export csv and data for all ever square allsites=st_intersection(st_as_sf(foundsites),squares[-selection]) for(g in (1:length(squares))[-selection]){ curr=allsites[allsites$ID==g,] coords=st_coordinates(curr) write.csv(file=paste0(&quot;square_&quot;,g,&quot;.csv&quot;),cbind.data.frame(lon=coords[,1],lat=coords[,2],dates=curr$dates,economy=curr$culture)) } ld=strsplit(inter$dates,&quot; \\\\| &quot;) ld=lapply(ld,function(i)gsub(&quot; ± .*&quot;,&quot;&quot;,i)) inter$start=sapply(ld,max) inter$end=sapply(ld,min) Some maps we use and did for fake papers and social media etc… ## plotting oldschool map plot(height.wat,col=adjustcolor(&quot;light blue&quot;,.4),reset=F,legend=F,axes=F) contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels=&quot;&quot;,bg=&quot;light blue&quot;,add=T) plot(st_geometry(inter),pch=4,add=T,lwd=.3) plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=.8,col=as.factor(inter$culture),alpha=.8) box() old=inter[inter$start&gt;7180,] ne=inter[inter$start&gt;6800 &amp; inter$end&lt;6900,] plot(height.wat,col=adjustcolor(&quot;light blue&quot;,.4),reset=F,legend=F,axes=F) contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels=&quot;&quot;,bg=&quot;light blue&quot;,add=T) plot(st_geometry(old),pch=4,add=T,lwd=.5,cex=3) plot(st_geometry(old),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(old$culture),alpha=.8) box() plot(height.wat,col=adjustcolor(&quot;light blue&quot;,.4),reset=F,legend=F,axes=F) contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels=&quot;&quot;,bg=&quot;light blue&quot;,add=T) plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3) plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8) box() plot(height.wat,col=adjustcolor(&quot;light blue&quot;,.4),reset=F,legend=F,axes=F) contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels=&quot;&quot;,bg=&quot;light blue&quot;,add=T) plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3) plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8) box() plot(height.wat,col=adjustcolor(&quot;light blue&quot;,.4),reset=F,legend=F,axes=F) contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.1,labels=&quot;&quot;,bg=&quot;light blue&quot;,add=T) plot(st_geometry(ne),pch=4,add=T,lwd=.5,cex=3) plot(st_geometry(ne),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(ne$culture),alpha=.8) box() More maps for twitter: plot(height.wat,col=adjustcolor(&quot;light blue&quot;,.4),reset=F,legend=F,axes=F) contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.2,labels=&quot;&quot;,bg=&quot;light blue&quot;,add=T) plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3) plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8) box() sel=inter[c(20,2,15,36),] text(st_coordinates(sel),sel$sitesnames,cex=.8,pos=c(1,2,2,4)) text(x = -1, y = .7, labels = &quot;❤️&quot;, adj = c(0, 0), cex = 3, col = &quot;black&quot;, font = 1) text(x = -1, y = 1.2, labels = &quot;🔥 &quot;, adj = c(0, 0), cex = 3, col = &quot;black&quot;, font = 1) text(x = -1, y = 1.2, labels = &quot;⚔️ &quot;, adj = c(0, 0), cex = 3, col = &quot;black&quot;, font = 1) text(x = -1.2, y = 1.8/2, labels = &quot;???? &quot;, adj=c(0,0), cex = 3, col = &quot;black&quot;, font = 1) More maps!! (the coolest) col_ramp &lt;- colorRampPalette(c(&quot;light blue&quot;,terrain.colors(10)[6], &quot;#54843f&quot;,&quot;grey&quot;,&quot;white&quot;)) plotMap(height.ras,height.wat) contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.2,labels=&quot;&quot;,bg=&quot;light blue&quot;,add=T) plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3) plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8) coastline=st_cast(st_as_sf(as.polygons(height.ras&gt;mean(height.ras[])))[2,],&quot;MULTILINESTRING&quot;) plot(coastline,add=T,lwd=1.1,col=&quot;black&quot;) box() sel=inter[c(20,2,15,36),] text(st_coordinates(sel),sel$sitesnames,cex=.8,pos=c(1,2,2,4)) col_ramp &lt;- colorRampPalette(c(&quot;light blue&quot;,terrain.colors(10)[6], &quot;#54843f&quot;,&quot;grey&quot;,&quot;white&quot;)) plotMap(height.ras,height.wat) contour(height.ras,levels=seq(5,300,15),axes=F,ann=F,lwd=.2,labels=&quot;&quot;,bg=&quot;light blue&quot;,add=T) plot(st_geometry(inter),pch=4,add=T,lwd=.5,cex=3) plot(st_geometry(inter),pch=20,add=T,lwd=.2,cex=1.8,col=as.factor(inter$culture),alpha=.8) coastline=st_cast(st_as_sf(as.polygons(height.ras&gt;mean(height.ras[])))[2,],&quot;MULTILINESTRING&quot;) plot(coastline,add=T,lwd=1.1,col=&quot;black&quot;) box() sel=inter[c(20,2,15,36),] text(st_coordinates(sel),sel$sitesnames,cex=.8,pos=c(1,2,2,4)) #text(x = -1, y = .7, labels = &quot;🍻&quot;, adj = c(0, 0), cex = 3, col = &quot;black&quot;, font = 1) text(x = -3.4, y = .7, labels = &quot;🍻 &quot;, adj = c(0, 0), cex = 10, col = &quot;black&quot;, font = 1) text(x = -1.8, y = .7, labels = &quot;👍 &quot;, adj = c(0, 0), cex = 8, col = &quot;black&quot;, font = 1) text(x = -.5, y = .7, labels = &quot;🍔 &quot;, adj = c(0, 0), cex = 6, col = &quot;black&quot;, font = 1) #text(x = -1, y = 1.2, labels = &quot;⚔️ &quot;, adj = c(0, 0), cex = 3, col = &quot;black&quot;, font = 1) #text(x = -1.2, y = 1.8/2, labels = &quot;???? &quot;, adj=c(0,0), cex = 3, col = &quot;black&quot;, font = 1) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
